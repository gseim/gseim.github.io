
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Newton-Raphson method &#8212; GSEIM 0.0.1 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Numerical methods for ODEs" href="numerical.html" />
    <link rel="prev" title="Modified nodal analysis" href="mna.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="newton-raphson-method">
<span id="nr"></span><h1>Newton-Raphson method<a class="headerlink" href="#newton-raphson-method" title="Permalink to this headline">¶</a></h1>
<p>Nonlinear equations arise in a wide variety of electronic and
power electronic circuits, and they need to be solved using an
iterative method. The Newton-Raphson (NR) iterative method
is commonly used for solving nonlinear equations because of
its excellent convergence properties. GSEIM also employs the
NR method, and it would be useful for GSEIM users to be
familiar with the functioning of the NR method.</p>
<p>To begin with, let us see where the NR method comes from.</p>
<div class="section" id="single-equation">
<span id="nr-single-eq"></span><h2>Single equation<a class="headerlink" href="#single-equation" title="Permalink to this headline">¶</a></h2>
<p>Consider the equation
<span class="math notranslate nohighlight">\(f(x) = 0\)</span>. Let <span class="math notranslate nohighlight">\(x = r\)</span> be the root (assumed to be single and real),
i.e., <span class="math notranslate nohighlight">\(f(r) = 0\)</span>. Let us say that we have some idea of the root in
the form of an <em>initial guess</em> <span class="math notranslate nohighlight">\(x^{(0)}\)</span>. The goal of the NR
method is to iteratively refine this value so that <span class="math notranslate nohighlight">\(f(x) = 0\)</span>
is satisfied to a higher accuracy with every NR iteration. We denote
the successive values of <span class="math notranslate nohighlight">\(x\)</span> by
<span class="math notranslate nohighlight">\(x^{(0)}\)</span>,
<span class="math notranslate nohighlight">\(x^{(1)}\)</span>,
<span class="math notranslate nohighlight">\(x^{(2)}\)</span>,
<span class="math notranslate nohighlight">\(\cdots\)</span></p>
<p>Consider <span class="math notranslate nohighlight">\(x = x^{(i)}\)</span>. Expanding <span class="math notranslate nohighlight">\(f(x)\)</span> around this value, we get</p>
<div class="math notranslate nohighlight" id="equation-eq-nr-1">
<span class="eqno">(58)<a class="headerlink" href="#equation-eq-nr-1" title="Permalink to this equation">¶</a></span>\[f(x^{(i)} + \Delta x^{(i)}) =
f(x^{(i)})
+ \Delta x^{(i)}\,\left.\displaystyle\frac{df}{dx}\right|_{x^{(i)}}
+ \displaystyle\frac{(\Delta x^{(i)})^2}{2!}\,\left.\displaystyle\frac{d^2f}{dx^2}\right|_{x^{(i)}}
+ \cdots\]</div>
<p>We seek the value of <span class="math notranslate nohighlight">\(\Delta x^{(i)}\)</span> which will satisfy
<span class="math notranslate nohighlight">\(f(x^{(i)} + \Delta x^{(i)}) = 0\)</span>, assuming that the
contribution from second- and higher-order terms is small
compared to the first term, i.e.,</p>
<div class="math notranslate nohighlight" id="equation-eq-nr-2">
<span class="eqno">(59)<a class="headerlink" href="#equation-eq-nr-2" title="Permalink to this equation">¶</a></span>\[f(x^{(i)} + \Delta x^{(i)}) \approx
f(x^{(i)})
+ \Delta x^{(i)}\,\left.\displaystyle\frac{df}{dx}\right|_{x^{(i)}}
= 0,~{\textrm{or}}~~
\Delta x^{(i)} = -\,\displaystyle\frac{f(x^{(i)})}{\left.\displaystyle\frac{df}{dx}\right|_{x^{(i)}}}\,.\]</div>
<p>If our assumption (that only the first term in <span class="math notranslate nohighlight">\(\Delta x^{(i)}\)</span> is significant)
is indeed valid, our job is done: we simply add
<span class="math notranslate nohighlight">\(\Delta x^{(i)}\)</span> to
<span class="math notranslate nohighlight">\(x^{(i)}\)</span>, and that gives us the solution. If not, we treat
<span class="math notranslate nohighlight">\(x^{(i)}+\Delta x^{(i)}\)</span> as the next candidate for <span class="math notranslate nohighlight">\(x\)</span>
(i.e., <span class="math notranslate nohighlight">\(x^{(i+1)} = x^{(i)}+\Delta x^{(i)}\)</span>), perform
another NR iteration, and so on. Let us illustrate this
procedure with an example.</p>
<p>Consider <span class="math notranslate nohighlight">\(f(x)\)</span> given by</p>
<div class="math notranslate nohighlight" id="equation-eq-nr-3">
<span class="eqno">(60)<a class="headerlink" href="#equation-eq-nr-3" title="Permalink to this equation">¶</a></span>\[f(x) =
a_3 x^3 +
a_2 x^2 +
a_1 x +
a_0,\]</div>
<p>with
<span class="math notranslate nohighlight">\(a_3\hspace{-1mm}=\hspace{-1mm}1\)</span>,
<span class="math notranslate nohighlight">\(a_2\hspace{-1mm}=\hspace{-1mm}-3.2\)</span>,
<span class="math notranslate nohighlight">\(a_1\hspace{-1mm}=\hspace{-1mm}8.7\)</span>,
<span class="math notranslate nohighlight">\(a_0\hspace{-1mm}=\hspace{-1mm}-14.3\)</span>.</p>
<p>The equation <span class="math notranslate nohighlight">\(f(x) = 0\)</span> has a real root at <span class="math notranslate nohighlight">\(x = 2.2\)</span> as seen
in the following figure.</p>
<a class="reference internal image-reference" href="_images/nr1a.png"><img alt="f(x) example 1" src="_images/nr1a.png" style="width: 320px;" /></a>
<p>The following C++ program performs NR iterations to obtain the root.</p>
<div class="highlight-text notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32</pre></div></td><td class="code"><div class="highlight"><pre><span></span>#include &lt;iostream&gt;
#include &lt;iomanip&gt;
#include &lt;math.h&gt;
using namespace std;

int main ()
{
   double x,f,dfdx,delx,tolr,r;
   double a3,a2,a1,a0;
   double x2,x3;

   a3 = 1.0; a2 = -3.2; a1 = 8.7; a0 = -14.3;

   x = 4.0;        // initial guess
   tolr = 1.0e-8;  // tolerance
   r = 2.2;        // actual solution

   for (int i=0; i &lt; 10; i++) {
     x2 = x*x; x3 = x2*x;              // powers of x
     f = a3*x3 + a2*x2 + a1*x + a0;    // function
     dfdx = 3.0*a3*x2 + 2.0*a2*x + a1; // derivative
     delx = -f/dfdx;                   // correction delta_x

     cout &lt;&lt; std::setw(2) &lt;&lt; i &lt;&lt; &quot;  &quot;;
     cout &lt;&lt; std::scientific;
     cout &lt;&lt; x &lt;&lt; &quot;  &quot; &lt;&lt; f &lt;&lt; &quot;  &quot; &lt;&lt; delx &lt;&lt; &quot;  &quot; &lt;&lt; (x-r) &lt;&lt; endl;

     if (fabs(f) &lt; tolr) break;        // tolerance met; exit loop
     x = x + delx;                     // update x
   }
   return 0;
}
</pre></div>
</td></tr></table></div>
<p>The output of the program is shown below.</p>
<table border="1" class="docutils">
<colgroup>
<col width="8%" />
<col width="22%" />
<col width="23%" />
<col width="24%" />
<col width="23%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><span class="math notranslate nohighlight">\(i\)</span></th>
<th class="head"><span class="math notranslate nohighlight">\(x^{(i)}\)</span></th>
<th class="head"><span class="math notranslate nohighlight">\(f(x^{(i)})\)</span></th>
<th class="head"><span class="math notranslate nohighlight">\(\Delta x^{(i)}\)</span></th>
<th class="head"><span class="math notranslate nohighlight">\((x^{(i)}-r)\)</span></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>0</td>
<td><span class="math notranslate nohighlight">\(4.000000\times 10^{0}\)</span></td>
<td><span class="math notranslate nohighlight">\(3.330000\times 10^{1}\)</span></td>
<td><span class="math notranslate nohighlight">\(-1.070740\times 10^{0}\)</span></td>
<td><span class="math notranslate nohighlight">\(1.800000\times 10^{0}\)</span></td>
</tr>
<tr class="row-odd"><td>1</td>
<td><span class="math notranslate nohighlight">\(2.929260\times 10^{0}\)</span></td>
<td><span class="math notranslate nohighlight">\(8.861467\times 10^{0}\)</span></td>
<td><span class="math notranslate nohighlight">\(-5.646248\times 10^{-1}\)</span></td>
<td><span class="math notranslate nohighlight">\(7.292605\times 10^{-1}\)</span></td>
</tr>
<tr class="row-even"><td>2</td>
<td><span class="math notranslate nohighlight">\(2.364636\times 10^{0}\)</span></td>
<td><span class="math notranslate nohighlight">\(1.601388\times 10^{0}\)</span></td>
<td><span class="math notranslate nohighlight">\(-1.548606\times 10^{-1}\)</span></td>
<td><span class="math notranslate nohighlight">\(1.646356\times 10^{-1}\)</span></td>
</tr>
<tr class="row-odd"><td>3</td>
<td><span class="math notranslate nohighlight">\(2.209775\times 10^{0}\)</span></td>
<td><span class="math notranslate nohighlight">\(8.966910\times 10^{-2}\)</span></td>
<td><span class="math notranslate nohighlight">\(-9.739489\times 10^{-3}\)</span></td>
<td><span class="math notranslate nohighlight">\(9.774978\times 10^{-3}\)</span></td>
</tr>
<tr class="row-even"><td>4</td>
<td><span class="math notranslate nohighlight">\(2.200035\times 10^{0}\)</span></td>
<td><span class="math notranslate nohighlight">\(3.243738\times 10^{-4}\)</span></td>
<td><span class="math notranslate nohighlight">\(-3.548854\times 10^{-5}\)</span></td>
<td><span class="math notranslate nohighlight">\(3.548901\times 10^{-5}\)</span></td>
</tr>
<tr class="row-odd"><td>5</td>
<td><span class="math notranslate nohighlight">\(2.200000\times 10^{0}\)</span></td>
<td><span class="math notranslate nohighlight">\(4.282173\times 10^{-9}\)</span></td>
<td><span class="math notranslate nohighlight">\(-4.685091\times 10^{-10}\)</span></td>
<td><span class="math notranslate nohighlight">\(4.685092\times 10^{-10}\)</span></td>
</tr>
</tbody>
</table>
<p>Note how quickly the NR process converges to the root. After three
iterations, we already have an accuracy of 0.44%. This rapid
convergence is the reason for the popularity of the NR method.
Near convergence, the “errors” for iterations <span class="math notranslate nohighlight">\(i\)</span> and
<span class="math notranslate nohighlight">\((i+1)\)</span> are related by</p>
<div class="math notranslate nohighlight" id="equation-eq-nr-4">
<span class="eqno">(61)<a class="headerlink" href="#equation-eq-nr-4" title="Permalink to this equation">¶</a></span>\[\epsilon ^{(i+1)} = k\left[\epsilon^{(i)}\right]^2\,,\]</div>
<p>where
<span class="math notranslate nohighlight">\(\epsilon^{(i)} = \left|x^{(i)}-r\right|\)</span> is the deviation of
<span class="math notranslate nohighlight">\(x^{(i)}\)</span> from the root <span class="math notranslate nohighlight">\(r\)</span>. The factor
<span class="math notranslate nohighlight">\(k \approx g''(r)/2\)</span>, i.e.,
<span class="math notranslate nohighlight">\(\displaystyle\frac{1}{2}\left.\displaystyle\frac{d^2f}{dx^2}\right|_{x=r}\)</span>.
Eq. <a class="reference internal" href="#equation-eq-nr-4">(61)</a> explains why the error goes down so dramatically as the NR
process converges. Because of the second power in Eq. <a class="reference internal" href="#equation-eq-nr-4">(61)</a>, the NR
process is said to have <em>quadratic convergence</em>.</p>
</div>
<div class="section" id="extension-to-set-of-equations">
<span id="nr-set-of-equations"></span><h2>Extension to set of equations<a class="headerlink" href="#extension-to-set-of-equations" title="Permalink to this headline">¶</a></h2>
<p>The NR method can be generalised to a system of <span class="math notranslate nohighlight">\(N\)</span> equations in <span class="math notranslate nohighlight">\(N\)</span> variables
given by</p>
<div class="math notranslate nohighlight" id="equation-eq-nr-5">
<span class="eqno">(62)<a class="headerlink" href="#equation-eq-nr-5" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
 f_1 (x_1,x_2,~.~.~,x_N)&amp;=0,\\
 f_2 (x_1,x_2,~.~.~,x_N)&amp;=0,\\
 ~~~~~~~~~~~~~ \vdots &amp; \\
 f_N (x_1,x_2,~.~.~,x_N)&amp;=0.
\end{align}\end{split}\]</div>
<p>In this case, we define a solution <em>vector</em>,</p>
<div class="math notranslate nohighlight" id="equation-eq-nr-6">
<span class="eqno">(63)<a class="headerlink" href="#equation-eq-nr-6" title="Permalink to this equation">¶</a></span>\[{\bf x^{(i)}}=
 \left[
 \begin{array}{c}
   x_1^{(i)}\cr x_2^{(i)}\cr ..\cr ~~\cr x_N^{(i)}\cr
 \end{array}
 \right]~.\]</div>
<p>We start with an initial guess for the solution
vector, i.e.,
<span class="math notranslate nohighlight">\(x_1^{(0)}\)</span>,
<span class="math notranslate nohighlight">\(x_2^{(0)}\)</span>,
<span class="math notranslate nohighlight">\(\cdots\)</span>,
<span class="math notranslate nohighlight">\(x_N^{(0)}\)</span>.
Note that, in practice, it is often difficult to come up with a
good initial guess, and in the absence of a better alternative,
<span class="math notranslate nohighlight">\(x_1^{(i)} = 0\)</span>,
<span class="math notranslate nohighlight">\(x_2^{(i)} = 0\)</span>, <span class="math notranslate nohighlight">\(\cdots\)</span>
may be used.
The correction vector in the <span class="math notranslate nohighlight">\(i^{\mathrm{th}}\)</span> iteration,
<span class="math notranslate nohighlight">\(\Delta {\bf{x}}^{(i)}\)</span> is computed as</p>
<div class="math notranslate nohighlight" id="equation-eq-nr-8">
<span class="eqno">(64)<a class="headerlink" href="#equation-eq-nr-8" title="Permalink to this equation">¶</a></span>\[\Delta x^{(i)} = -\left[{\bf{J}}^{(i)}\right]^{-1}{\bf{f}}^{(i)},\]</div>
<p>where</p>
<div class="math notranslate nohighlight" id="equation-eq-nr-9">
<span class="eqno">(65)<a class="headerlink" href="#equation-eq-nr-9" title="Permalink to this equation">¶</a></span>\[\begin{split}{\bf f}^{(i)}=
 \left[
 \begin{array}{c}
    f_1({\bf x}^{(i)})\cr f_2({\bf x}^{(i)})\cr ..\cr
    f_N({\bf x}^{(i)})\cr
 \end{array}
 \right],~~~
    {\bf J}^{(i)}=
    \left[
    \begin{array}{cccc}
    \displaystyle\frac{\partial f_1}{\partial x_1}&amp;
    \displaystyle\frac{\partial f_1}{\partial x_2}&amp;
    .~.&amp;
    \displaystyle\frac{\partial f_1}{\partial x_N}
    \\[0.15in]
    \displaystyle\frac{\partial f_2}{\partial x_1}&amp;
    \displaystyle\frac{\partial f_2}{\partial x_2}&amp;
    .~.&amp;
    \displaystyle\frac{\partial f_2}{\partial x_N}
    \\
    .~.&amp;
    .~.&amp;
    .~.&amp;
    \\[0.15in]
    \displaystyle\frac{\partial f_N}{\partial x_1}&amp;
    \displaystyle\frac{\partial f_N}{\partial x_2}&amp;
    .~.&amp;
    \displaystyle\frac{\partial f_N}{\partial x_N}
    \end{array}
    \right],\end{split}\]</div>
<p>and the functions and derivatives are evaluated at the current values,
<span class="math notranslate nohighlight">\(x_1^{(i)}\)</span>,
<span class="math notranslate nohighlight">\(x_2^{(i)}\)</span>,
<span class="math notranslate nohighlight">\(\cdots\)</span>,
<span class="math notranslate nohighlight">\(x_N^{(i)}\)</span>. The NR procedure is otherwise similar to that for the
one variable case, as seen in the flow-chart below.</p>
<a class="reference internal image-reference" href="_images/nr2.png"><img alt="f(x) flow chart" src="_images/nr2.png" style="width: 350px;" /></a>
</div>
<div class="section" id="convergence-criteria">
<span id="nr-convergence-criteria"></span><h2>Convergence criteria<a class="headerlink" href="#convergence-criteria" title="Permalink to this headline">¶</a></h2>
<p>In the NR method, we need to set a “convergence criterion” to determine
when to stop the NR iterations. In the program given in the
<a class="reference internal" href="#nr-single-eq"><span class="std std-ref">single equation</span></a> section, for example, the variable
<code class="docutils literal notranslate"><span class="pre">tolr</span></code> (tolerance) served this purpose.
The following convergence criteria are commonly used.</p>
<ul>
<li><p class="first">Norm of <span class="math notranslate nohighlight">\({\bf{f}}\)</span>: In this case, we check if the function values
are small. Typically, the 2-norm, defined as</p>
<p><span class="math notranslate nohighlight">\(||\,{\bf{f}}\,||_2 = \left[\displaystyle\sum_{i=1}^{N}f_i^2\right]^{1/2}\)</span>,</p>
<p>is computed, and the NR iterations are said to converge if
<span class="math notranslate nohighlight">\(||{\bf{f}}||_2 &lt; \epsilon\)</span>, a suitable tolerance value.
This is an <em>absolute</em> convergence criterion since our
goal is precisely to solve the set of equations to get
<span class="math notranslate nohighlight">\(f_i = 0\)</span> (for each <span class="math notranslate nohighlight">\(i\)</span>) which means in practice that
<span class="math notranslate nohighlight">\(|f_i|\)</span> (or somewhat equivalently, the 2-norm) should be made
as small as possible.</p>
</li>
<li id="delx-norm"><p class="first"><span class="math notranslate nohighlight">\(\Delta{\bf{x}}\)</span> norm: Here, we check if each component of
the correction vector is sufficiently small <em>relative</em> to its current
value, i.e.,
<span class="math notranslate nohighlight">\(|\Delta x_i| &lt; \epsilon  \,|x_i|\)</span>.
This is a <em>relative</em> criterion and is based on the fact that, as
the NR process converges, <span class="math notranslate nohighlight">\(\Delta x_i\)</span> become
smaller, as we have seen in the <a class="reference internal" href="#nr-single-eq"><span class="std std-ref">one-variable example</span></a>.</p>
</li>
<li id="spice-norm"><p class="first">SPICE convergence criterion: In SPICE, a tolerance is computed for
each variable as follows:</p>
<div class="math notranslate nohighlight" id="equation-eq-nr-spice-1">
<span class="eqno">(66)<a class="headerlink" href="#equation-eq-nr-spice-1" title="Permalink to this equation">¶</a></span>\[\tau _i = k_{\mathrm{rel}}\times
{\textrm{max}}
\left(
 |x_i^{(k)}|,
 |x_i^{(k+1)}|
\right)
+ \tau _{\mathrm{abs}},\]</div>
<p>where
<span class="math notranslate nohighlight">\(k_{\mathrm{rel}}\)</span> (typically 0.001) and
<span class="math notranslate nohighlight">\(\tau _{\mathrm{abs}}\)</span> are constants, and
<span class="math notranslate nohighlight">\(x_i^{(k)}\)</span> denotes the value of <span class="math notranslate nohighlight">\(x_i\)</span> in the
<span class="math notranslate nohighlight">\(k^{\mathrm{th}}\)</span> iteration.
The first term specifies a <em>relative</em> tolerance
while the second term is an <em>absolute</em> tolerance.
If <span class="math notranslate nohighlight">\(x\)</span> is of type voltage, <span class="math notranslate nohighlight">\(\tau _{\mathrm{abs}}\)</span> may be
<span class="math notranslate nohighlight">\(0.01\,{\textrm{mV}}\)</span>, for
example. Convergence is said to be attained if</p>
<div class="math notranslate nohighlight" id="equation-eq-nr-spice-2">
<span class="eqno">(67)<a class="headerlink" href="#equation-eq-nr-spice-2" title="Permalink to this equation">¶</a></span>\[|x_i^{(k+1)}-x_i^{(k)}| &lt; \tau _i.
\label{eq_nr_spice_2}\]</div>
<p>SPICE uses the term <code class="docutils literal notranslate"><span class="pre">RELTOL</span></code> for <span class="math notranslate nohighlight">\(k_{\mathrm{rel}}\)</span>,
<code class="docutils literal notranslate"><span class="pre">VNTOL</span></code> for <span class="math notranslate nohighlight">\(\tau _{\mathrm{abs}}\)</span> for node voltage variables, and
<code class="docutils literal notranslate"><span class="pre">ABSTOL</span></code> for <span class="math notranslate nohighlight">\(\tau _{\mathrm{abs}}\)</span> for currents.
In a variety of electronic circuits,
the tried and tested SPICE convergence criterion is found to work well.</p>
</li>
</ul>
<p>Why are there so many different convergence criteria?
Isn’t there a simple “universal” convergence criterion which
we can use for all problems? To answer this question, let us
take a closer look at convergence of the NR process.</p>
<p>As we have seen earlier, the “error,” i.e., the difference
between the numerical solution and the actual solution, goes down
dramatically with each iteration, as the NR process converges.
If our computer had infinite precision, the error can be reduced
to arbitrarily small values by performing additional NR iterations.
In practice, computers have a finite precision.
With single-precision (32-bit) numbers, the smallest number that can
be represented is about <span class="math notranslate nohighlight">\(10^{-38}\)</span>, and the largest number is
about <span class="math notranslate nohighlight">\(10^{+38}\)</span>.
With double-precision (64-bit) numbers, the smallest and largest numbers
are about <span class="math notranslate nohighlight">\(10^{-308}\)</span> and <span class="math notranslate nohighlight">\(10^{+308}\)</span>, respectively.
Furthermore, because of the finite number of bits used for the mantissa,
only a finite number of real numbers can be represented, say,
<span class="math notranslate nohighlight">\(r_1\)</span>,
<span class="math notranslate nohighlight">\(r_2\)</span>,
<span class="math notranslate nohighlight">\(r_3\)</span>,
<span class="math notranslate nohighlight">\(\cdots\)</span>
Any number falling between <span class="math notranslate nohighlight">\(r_k\)</span> and <span class="math notranslate nohighlight">\(r_{k+1}\)</span> is rounded off to
<span class="math notranslate nohighlight">\(r_k\)</span> or <span class="math notranslate nohighlight">\(r_{k+1}\)</span>, leading to a
“round-off error”
which is of the order of
<span class="math notranslate nohighlight">\(10^{-7}\)</span> for single-precision numbers and
<span class="math notranslate nohighlight">\(10^{-16}\)</span> for double-precision numbers.</p>
<p>The round-off error, however small, is finite, and it limits the
accuracy that we can achieve with the NR method.
If our convergence check is too stringent,
convergence will not be attained, and
the NR process will get terminated with
an error message (although the solution may already be sufficiently
accurate). If it is too loose, we end up with the wrong solution.
Setting an appropriate convergence criterion is therefore crucial
in implementing the NR method, as illustrated in the following example.</p>
<p>Consider the systems of equations,</p>
<div class="math notranslate nohighlight" id="equation-eq-nr-10a">
<span class="eqno">(68)<a class="headerlink" href="#equation-eq-nr-10a" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
 f_1 (x_1,x_2)&amp;\equiv k\, (x_1+x_2-6\sqrt{3}) &amp;= 0,\\
 f_2 (x_1,x_2)&amp;\equiv 10x_1^2 -x_2^2+45 &amp;= 0.
\end{align}\end{split}\]</div>
<p>Clearly, the solution would not depend on <span class="math notranslate nohighlight">\(k\)</span> since
it is simply a scaling factor.
We want to solve this system of equations with the initial guess
<span class="math notranslate nohighlight">\(x_1 = 1\)</span>,
<span class="math notranslate nohighlight">\(x_2 = 1\)</span>.
With this initial guess, the NR method converges
to the solution
<span class="math notranslate nohighlight">\(x_1 = \sqrt{3}\)</span>,
<span class="math notranslate nohighlight">\(x_2 = 5\sqrt{3}\)</span>.
(Note that the above system of equations actually has another
solution; but only the solution
<span class="math notranslate nohighlight">\(x_1 = \sqrt{3}\)</span>,
<span class="math notranslate nohighlight">\(x_2 = 5\sqrt{3}\)</span>
is relevant for our discussion, considering the initial guess we have used.)</p>
<p>The <span class="math notranslate nohighlight">\(||{\bf{f}}||_2\)</span> norm at each NR iteration obtained using
single-precision <code class="docutils literal notranslate"><span class="pre">(float)</span></code> numbers is shown in the following table.</p>
<table border="1" class="docutils">
<colgroup>
<col width="8%" />
<col width="46%" />
<col width="46%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head" rowspan="2">i</th>
<th class="head" colspan="2"><span class="math notranslate nohighlight">\(||{\bf{f}}||_2\)</span></th>
</tr>
<tr class="row-even"><th class="head"><span class="math notranslate nohighlight">\(k = 1\)</span></th>
<th class="head"><span class="math notranslate nohighlight">\(k = 10^5\)</span></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-odd"><td>0</td>
<td><code class="docutils literal notranslate"><span class="pre">5.464824e+01</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">8.392304e+05</span></code></td>
</tr>
<tr class="row-even"><td>1</td>
<td><code class="docutils literal notranslate"><span class="pre">7.306992e+01</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">7.306991e+01</span></code></td>
</tr>
<tr class="row-odd"><td>2</td>
<td><code class="docutils literal notranslate"><span class="pre">6.915764e+02</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">6.915771e+02</span></code></td>
</tr>
<tr class="row-even"><td>3</td>
<td><code class="docutils literal notranslate"><span class="pre">1.559785e+02</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">1.559788e+02</span></code></td>
</tr>
<tr class="row-odd"><td>4</td>
<td><code class="docutils literal notranslate"><span class="pre">2.633286e+01</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">2.633291e+01</span></code></td>
</tr>
<tr class="row-even"><td>5</td>
<td><code class="docutils literal notranslate"><span class="pre">1.710737e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">1.710923e+00</span></code></td>
</tr>
<tr class="row-odd"><td>6</td>
<td><code class="docutils literal notranslate"><span class="pre">9.535313e-03</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">2.567794e-02</span></code></td>
</tr>
<tr class="row-even"><td>7</td>
<td><code class="docutils literal notranslate"><span class="pre">7.662848e-06</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">7.152557e-02</span></code></td>
</tr>
<tr class="row-odd"><td>8</td>
<td><code class="docutils literal notranslate"><span class="pre">2.870940e-06</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">2.384186e-02</span></code></td>
</tr>
<tr class="row-even"><td>9</td>
<td><code class="docutils literal notranslate"><span class="pre">2.870940e-06</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">2.384186e-02</span></code></td>
</tr>
</tbody>
</table>
<p>We can see that
<span class="math notranslate nohighlight">\(||{\bf{f}}||_2\)</span>
reduces as the NR process converges to the solution, but after some point
(iteration 8), it does not reduce any further.
With <span class="math notranslate nohighlight">\(k = 1\)</span> in Eq. <a class="reference internal" href="#equation-eq-nr-10a">(68)</a>,  the smallest value attained by
<span class="math notranslate nohighlight">\(||{\bf{f}}||_2\)</span> is <span class="math notranslate nohighlight">\(2.87\times 10^{-6}\)</span>, whereas with
<span class="math notranslate nohighlight">\(k = 10^5\)</span>,
it is <span class="math notranslate nohighlight">\(2.38\times 10^{-2}\)</span>, which is four orders larger.</p>
<p>Does it mean that the solution we obtain with
<span class="math notranslate nohighlight">\(k = 10^5\)</span> is less accurate? In the following table, let us look at how
<span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x_2\)</span> evolve.</p>
<table border="1" class="docutils">
<colgroup>
<col width="4%" />
<col width="25%" />
<col width="23%" />
<col width="25%" />
<col width="23%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td rowspan="2">i</td>
<td colspan="2"><span class="math notranslate nohighlight">\(k = 1\)</span></td>
<td colspan="2"><span class="math notranslate nohighlight">\(k = 10^5\)</span></td>
</tr>
<tr class="row-even"><td><span class="math notranslate nohighlight">\(x_1\)</span></td>
<td><span class="math notranslate nohighlight">\(x_2\)</span></td>
<td><span class="math notranslate nohighlight">\(x_1\)</span></td>
<td><span class="math notranslate nohighlight">\(x_2\)</span></td>
</tr>
<tr class="row-odd"><td>0</td>
<td><code class="docutils literal notranslate"><span class="pre">1.000000e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">1.000000e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">1.000000e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">1.000000e+00</span></code></td>
</tr>
<tr class="row-even"><td>1</td>
<td><code class="docutils literal notranslate"><span class="pre">-6.916087e-01</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">1.108391e+01</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">-6.916087e-01</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">1.108391e+01</span></code></td>
</tr>
<tr class="row-odd"><td>2</td>
<td><code class="docutils literal notranslate"><span class="pre">8.074338e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">2.317966e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">8.074343e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">2.317963e+00</span></code></td>
</tr>
<tr class="row-even"><td>3</td>
<td><code class="docutils literal notranslate"><span class="pre">3.911292e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">6.481012e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">3.911294e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">6.481010e+00</span></code></td>
</tr>
<tr class="row-odd"><td>4</td>
<td><code class="docutils literal notranslate"><span class="pre">2.200773e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">8.191531e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">2.200774e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">8.191530e+00</span></code></td>
</tr>
<tr class="row-even"><td>5</td>
<td><code class="docutils literal notranslate"><span class="pre">1.764788e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">8.627517e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">1.764789e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">8.627516e+00</span></code></td>
</tr>
<tr class="row-odd"><td>6</td>
<td><code class="docutils literal notranslate"><span class="pre">1.732234e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">8.660070e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">1.732234e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">8.660070e+00</span></code></td>
</tr>
<tr class="row-even"><td>7</td>
<td><code class="docutils literal notranslate"><span class="pre">1.732051e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">8.660254e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">1.732051e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">8.660254e+00</span></code></td>
</tr>
<tr class="row-odd"><td>8</td>
<td><code class="docutils literal notranslate"><span class="pre">1.732051e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">8.660254e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">1.732051e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">8.660254e+00</span></code></td>
</tr>
<tr class="row-even"><td>9</td>
<td><code class="docutils literal notranslate"><span class="pre">1.732051e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">8.660254e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">1.732051e+00</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">8.660254e+00</span></code></td>
</tr>
</tbody>
</table>
<p>We see that, after iteration 6, there is no difference between
<span class="math notranslate nohighlight">\(k = 1\)</span> and
<span class="math notranslate nohighlight">\(k = 10^5\)</span>, and in fact these
values coincide with the expected solution
(<span class="math notranslate nohighlight">\(x_1 = \sqrt{3}\)</span>,
<span class="math notranslate nohighlight">\(x_2 = 5\sqrt{3}\)</span>) up to six decimal places. In practice, we
would be fine with this level of accuracy.</p>
<p>Clearly, if the 2-norm is used as the convergence criterion, it needs to be
carefully assigned. In the above example,
a 2-norm of <span class="math notranslate nohighlight">\(10^{-3}\)</span> will work (i.e., the NR process
will exit after attaining convergence) for
<span class="math notranslate nohighlight">\(k = 1\)</span>, but not with
<span class="math notranslate nohighlight">\(k = 10^5\)</span>. This means that selection of the convergence
criterion must be made differently for different problems!
In reality, the situation is not so hopeless. For example, if
we are only interested in power electronic circuits, the default values
provided by GSEIM for the SPICE convergence criteria
would generally work well and may need to be tweaked only for
a few specific simulations.</p>
</div>
<div class="section" id="graphical-interpretation-of-the-nr-process">
<span id="nr-graphical"></span><h2>Graphical interpretation of the NR process<a class="headerlink" href="#graphical-interpretation-of-the-nr-process" title="Permalink to this headline">¶</a></h2>
<p>In the one-variable case, the NR process has a useful graphical
interpretation. The correction
<span class="math notranslate nohighlight">\(\Delta x^{(i)}\)</span>
in the <span class="math notranslate nohighlight">\(i^{\mathrm{th}}\)</span> NR iteration is given by</p>
<div class="math notranslate nohighlight" id="equation-eq-nr-11">
<span class="eqno">(69)<a class="headerlink" href="#equation-eq-nr-11" title="Permalink to this equation">¶</a></span>\[\Delta x^{(i)} = -\,\displaystyle\frac{f(x^{(i)})}{\left.\displaystyle\frac{df}{dx}\right|_{x^{(i)}}}\,.\]</div>
<p>Since <span class="math notranslate nohighlight">\(\left.\displaystyle\frac{df}{dx}\right|_{x^{(i)}}\)</span>
is the slope of the <span class="math notranslate nohighlight">\(f(x)\)</span> curve at
<span class="math notranslate nohighlight">\(x = x^{(i)}\)</span>, the magnitude of
<span class="math notranslate nohighlight">\(\Delta x^{(i)}\)</span> is given by drawing a tangent at the point
<span class="math notranslate nohighlight">\((x^{(i)},f(x^{(i)}))\)</span> and extending it to the <span class="math notranslate nohighlight">\(x\)</span>-axis, as shown
below.</p>
<a class="reference internal image-reference" href="_images/nr3.png"><img alt="graphical interpretation 1" src="_images/nr3.png" style="width: 380px;" /></a>
<p><span class="math notranslate nohighlight">\(x^{(i+1)} = x^{(i)} + \Delta x^{(i)}\)</span> is then obtained by
simply going from
<span class="math notranslate nohighlight">\(x^{(i)}\)</span>
in the negative <span class="math notranslate nohighlight">\(x\)</span>-direction if the sign of
<span class="math notranslate nohighlight">\(\left.\displaystyle\frac{df}{dx}\right|_{x^{(i)}}\)</span>
is positive (and <em>vice versa</em>) a distance of
<span class="math notranslate nohighlight">\(\Delta x^{(i)}\)</span>. This leads to the following interpretation
of the NR process.</p>
<ul class="simple">
<li>Draw a tangent at <span class="math notranslate nohighlight">\((x^{(i)},f(x^{(i)}))\)</span>.</li>
<li>Extend the tangent to the <span class="math notranslate nohighlight">\(x\)</span>-axis.</li>
<li>The point of intersection of the tangent with the <span class="math notranslate nohighlight">\(x\)</span>-axis
gives the next values of <span class="math notranslate nohighlight">\(x\)</span>, i.e., <span class="math notranslate nohighlight">\(x^{(i+1)}\)</span>.</li>
</ul>
<p>The NR process for Eq. <a class="reference internal" href="#equation-eq-nr-3">(60)</a> is shown in the following figure.
It is easy to see that, if <span class="math notranslate nohighlight">\(f(x)\)</span> is linear
(i.e., <span class="math notranslate nohighlight">\(f(x) = k_1x+ k_2\)</span>),
the NR process will converge in exactly one iteration.</p>
<a class="reference internal image-reference" href="_images/nr4a.png"><img alt="graphical interpretation 2" src="_images/nr4a.png" style="width: 600px;" /></a>
</div>
<div class="section" id="convergence-issues">
<span id="nr-convergence-issues"></span><h2>Convergence issues<a class="headerlink" href="#convergence-issues" title="Permalink to this headline">¶</a></h2>
<p>We have seen that the NR method has the desirable property of
rapid convergence. The big question is whether it will always
converge. The answer, unfortunately, is <strong>no</strong>. Convergence of the
NR method is guaranteed only if the initial guess is “sufficiently”
close to the solution (root). In the one-variable case, it can be
shown that, if</p>
<div class="math notranslate nohighlight" id="equation-eq-nr-12">
<span class="eqno">(70)<a class="headerlink" href="#equation-eq-nr-12" title="Permalink to this equation">¶</a></span>\[\displaystyle\frac{\left|f(x)f''(x)\right|}{(f'(x))^2} &lt; 1\]</div>
<p>for some interval <span class="math notranslate nohighlight">\((x_1,x_2)\)</span> containing the root <span class="math notranslate nohighlight">\(r\)</span>,
the NR method will converge for an initial guess
<span class="math notranslate nohighlight">\(x^{(0)}\)</span> lying in that interval. If not, the NR process may
not converge.</p>
<p>As an example, consider</p>
<div class="math notranslate nohighlight" id="equation-eq-nr-13">
<span class="eqno">(71)<a class="headerlink" href="#equation-eq-nr-13" title="Permalink to this equation">¶</a></span>\[f(x) = \tan ^{-1}(x-a).\]</div>
<p>For this function,</p>
<div class="math notranslate nohighlight" id="equation-eq-nr-14">
<span class="eqno">(72)<a class="headerlink" href="#equation-eq-nr-14" title="Permalink to this equation">¶</a></span>\[f_1(x) \equiv
\displaystyle\frac{f(x)f''(x)}{(f'(x))^2}
= -2(x-a)\tan ^{-1}(x-a).\]</div>
<p>The plots of (a) <span class="math notranslate nohighlight">\(f(x)\)</span> and (b) <span class="math notranslate nohighlight">\(f_1(x)\)</span>
for <span class="math notranslate nohighlight">\(a = 1.5\)</span> are shown below.</p>
<a class="reference internal image-reference" href="_images/nr5ab.png"><img alt="convergence issues 1" src="_images/nr5ab.png" style="width: 600px;" /></a>
<p>For <span class="math notranslate nohighlight">\(|f_1(x)| &lt; 1\)</span>, we need
<span class="math notranslate nohighlight">\(0.735 &lt; x &lt; 2.265\)</span>. If the initial guess is within this range,
the NR process for <span class="math notranslate nohighlight">\(f(x)\)</span> is guaranteed to converge
as seen in this example:</p>
<a class="reference internal image-reference" href="_images/nr8a.png"><img alt="convergence issues 2" src="_images/nr8a.png" style="width: 600px;" /></a>
<p>If the initial guess is outside the range
<span class="math notranslate nohighlight">\(0.735 &lt; x &lt; 2.265\)</span>, the NR process is not guaranteed to
converge. For example, in the figure below, we can clearly see
that the NR process is <em>diverging</em>, i.e., the solution is moving
away from the root with every iteration.</p>
<div class="figure" id="id1">
<span id="nr-atan-3"></span><a class="reference internal image-reference" href="_images/nr7a.png"><img alt="convergence issues 3" src="_images/nr7a.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-number">Fig. 1 </span><span class="caption-text">Divergence example</span></p>
</div>
<p>An equally catastrophic situation, in which the NR process oscillates
around the root, is shown below.</p>
<a class="reference internal image-reference" href="_images/nr9a.png"><img alt="convergence issues 4" src="_images/nr9a.png" style="width: 600px;" /></a>
<p>Failure of the NR procedure is not a hypothetical calamity; it is a
very real possibility in circuit simulation. Fortunately, some clever
ways have been devised to nudge the NR process toward convergence as
discussed in the following.</p>
<div class="section" id="damping-of-the-nr-iterations">
<span id="nr-damping-1"></span><h3>Damping of the NR iterations<a class="headerlink" href="#damping-of-the-nr-iterations" title="Permalink to this headline">¶</a></h3>
<p>Consider the one variable case. As we have seen earlier, the NR method
is related to the Taylor series of the function around the current value
<span class="math notranslate nohighlight">\(x^{(i)}\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-eq-nr-15">
<span class="eqno">(73)<a class="headerlink" href="#equation-eq-nr-15" title="Permalink to this equation">¶</a></span>\[f(x^{(i)} + \Delta x^{(i)}) =
f(x^{(i)})
+ \Delta x^{(i)}\,\left.\displaystyle\frac{df}{dx}\right|_{x^{(i)}}
+ {\textrm{higher-order~terms}}.\]</div>
<p>If the higher-order terms are small, the NR method is expected to work
well. Convergence problems can arise when they are not small. To be specific,
let us look at this
<a class="reference internal" href="#nr-atan-3"><span class="std std-ref">Divergence example</span></a>
in which the NR process diverges.
The slope at
<span class="math notranslate nohighlight">\((x^{(i)},f(x^{(i)}))\)</span>
corresponds to the first term of the Taylor series, and the curvature
is due to the higher-order terms. We note that the slope does take us
in the correct <em>direction</em> (i.e., toward the root), but because of the
curvature, we may end up going too far in that direction. The idea behind
damping of the NR process is to play it safe and go only part of the way.</p>
<p>In the standard NR process, the correction vector is computed as
<span class="math notranslate nohighlight">\(\Delta x^{(i)} = -\left[{\bf{J}}^{(i)}\right]^{-1}{\bf{f}}^{(i)}\)</span> and is
added to the current solution vector to obtain the next guess:</p>
<div class="math notranslate nohighlight" id="equation-eq-nr-16">
<span class="eqno">(74)<a class="headerlink" href="#equation-eq-nr-16" title="Permalink to this equation">¶</a></span>\[{\bf{x}}^{(i+1)} =
{\bf{x}}^{(i)} +
\Delta {\bf{x}}^{(i)}.\]</div>
<p>We can <em>dampen</em> or slow down the NR process by adding only a fraction of
the correction vector, i.e.,</p>
<div class="math notranslate nohighlight" id="equation-eq-nr-17">
<span class="eqno">(75)<a class="headerlink" href="#equation-eq-nr-17" title="Permalink to this equation">¶</a></span>\[{\bf{x}}^{(i+1)} =
{\bf{x}}^{(i)} +
k\, \Delta {\bf{x}}^{(i)},~~(0 &lt; k &lt; 1),\]</div>
<p>where <span class="math notranslate nohighlight">\(k\)</span> is the <strong>damping factor</strong>.</p>
<p>The following figure shows the effect of damping for the <a class="reference internal" href="#nr-atan-3"><span class="std std-ref">Divergence example</span></a>
with the same initial guess, viz.,
<span class="math notranslate nohighlight">\(x^{(0)} = 0\)</span>. In each iteration, we draw a tangent at
<span class="math notranslate nohighlight">\((x^{(i)},f(x^{(i)}))\)</span> as before, but instead of going all the way to
the intercept with the <span class="math notranslate nohighlight">\(x\)</span>-axis (the dashed line),  we go only a fraction
of the way to obtain the next iterate
<span class="math notranslate nohighlight">\(x^{(i+1)}\)</span>. The NR process is now seen to converge to the solution.</p>
<a class="reference internal image-reference" href="_images/nr10a.png"><img alt="damping 1" src="_images/nr10a.png" style="width: 600px;" /></a>
<p>If damping it so effective, should we always use it? Not really. Although
damping improves the chances of convergence, it slows down the NR process.
Damping should therefore be used only if the standard NR process fails
to converge. The following figure shows the effect of <span class="math notranslate nohighlight">\(k\)</span> for
<span class="math notranslate nohighlight">\(f(x) = \tan ^{-1}(x)\)</span> with <span class="math notranslate nohighlight">\(x^{(0)} = 1.5\)</span>. In this case, the
standard NR method fails, and therefore damping is useful. When <span class="math notranslate nohighlight">\(k\)</span> is small,
the convergence is slower. An efficient strategy is to use damping only in the
first few NR iterations and then use the standard NR process (i.e., make
<span class="math notranslate nohighlight">\(k = 1\)</span>) thereafter. In this way, we get convergence and also retain
the quadratic convergence property of the NR process when damping is lifted.
An example is shown in the same figure.</p>
<a class="reference internal image-reference" href="_images/nr11.png"><img alt="damping 2" src="_images/nr11.png" style="width: 600px;" /></a>
</div>
<div class="section" id="parameter-stepping">
<span id="nr-damping-2"></span><h3>Parameter stepping<a class="headerlink" href="#parameter-stepping" title="Permalink to this headline">¶</a></h3>
<p>Suppose we try to solve <span class="math notranslate nohighlight">\(f(x) = 0\)</span> with an initial guess
<span class="math notranslate nohighlight">\(x^{(0)}\)</span>,
and find that the standard NR method fails to converge. We can
then construct another function
<span class="math notranslate nohighlight">\(h(x) = f(x)+g(x)\)</span>, where <span class="math notranslate nohighlight">\(g(x)\)</span> is a suitable “auxiliary”
function. To be specific, let us consider
<span class="math notranslate nohighlight">\(g(x) = kx\)</span>. To begin with, <span class="math notranslate nohighlight">\(k\)</span> is made sufficiently large
(call it <span class="math notranslate nohighlight">\(k^{(0)}\)</span>), <span class="math notranslate nohighlight">\(h(x)\)</span> then takes an approximately linear form
<span class="math notranslate nohighlight">\(h^{(0)}(x) \approx k^{(0)}x\)</span>, and the NR method can be used
effectively to solve
<span class="math notranslate nohighlight">\(h^{(0)}(x) = 0\)</span> without any convergence issue. Let us denote
the solution obtained for
<span class="math notranslate nohighlight">\(h^{(0)}(x) = 0\)</span> by <span class="math notranslate nohighlight">\(r^{(0)}\)</span>. Next, we relax the parameter <span class="math notranslate nohighlight">\(k\)</span>
in <span class="math notranslate nohighlight">\(g(x)\)</span> to a smaller value <span class="math notranslate nohighlight">\(k^{(1)}\)</span> and solve
<span class="math notranslate nohighlight">\(h^{(1)}(x) \equiv f(x)+k^{(1)}x = 0\)</span>, using
<span class="math notranslate nohighlight">\(r^{(0)}\)</span> as the initial guess. Once again, the NR process is likely
to converge if
<span class="math notranslate nohighlight">\(k^{(1)}\)</span> is sufficiently close to
<span class="math notranslate nohighlight">\(k^{(0)}\)</span>. We repeat this process, making <span class="math notranslate nohighlight">\(k\)</span> progressively smaller.
Finally, when <span class="math notranslate nohighlight">\(k\)</span> is negligibly small,
<span class="math notranslate nohighlight">\(h(x) = f(x)+g(x) \approx f(x)\)</span>, and we have got the
solution for our original problem, <span class="math notranslate nohighlight">\(f(x) = 0\)</span>.</p>
<p>The above procedure in which
the parameter <span class="math notranslate nohighlight">\(k\)</span> is changed from a large value to zero
(or a negligibly small value)
in several steps may be called “parameter stepping.”
The following figure shows the effect of parameter stepping
when solving
<span class="math notranslate nohighlight">\(f(x) \equiv \tan ^{-1}(x-a) = 0\)</span> with
<span class="math notranslate nohighlight">\(a = 1.5\)</span>, and
<span class="math notranslate nohighlight">\(x^{(0)} = 0\)</span> as the initial guess. An auxiliary
function <span class="math notranslate nohighlight">\(g^{(i)}(x) = k^{(i)}\,x\)</span> is used, and
<span class="math notranslate nohighlight">\(h^{(i)}(x) = f(x) + g^{(i)}(x)\)</span> is solved with the
NR method. <span class="math notranslate nohighlight">\(x = 0\)</span> is used as the initial guess
for solving <span class="math notranslate nohighlight">\(h^{(0)} = 0\)</span>. Thereafter,
the solution <span class="math notranslate nohighlight">\(r^{(i-1)}\)</span> for
<span class="math notranslate nohighlight">\(h^{(i-1)} = 0\)</span> is used as the initial guess for solving
<span class="math notranslate nohighlight">\(h^{(i)} = 0\)</span>. The values of <span class="math notranslate nohighlight">\(k^{(i)}\)</span> for <span class="math notranslate nohighlight">\(i = 0\)</span> to 5
are 5, 2, 1, 0.5, 0.2, 0, respectively. The roots are denoted by crosses.</p>
<a class="reference internal image-reference" href="_images/nr12a.png"><img alt="damping 3" src="_images/nr12a.png" style="width: 600px;" /></a>
<p>In electronic circuits, there are many situations in which
no suitable initial guess is available. Parameter stepping
is useful in such cases. It can be carried out in different
forms.</p>
<ul class="simple">
<li><span class="math notranslate nohighlight">\(g_{\mathrm{min}}\)</span> <strong>stepping</strong>:
In this scheme, a conductance <span class="math notranslate nohighlight">\(g\)</span> (i.e., a resistance <span class="math notranslate nohighlight">\(1/g\)</span>) is added
from each circuit node to ground, as shown in the following figure.
If <span class="math notranslate nohighlight">\(g\)</span> is large (i.e., the resistance is small),
the nonlinear devices are essentially bypassed, the circuit reduces
to an approximately linear circuit, and the NR method converges
easily. Using the solution so obtained as the initial guess, the same
circuit with a lower value of <span class="math notranslate nohighlight">\(g\)</span> is then solved, and so on. Finally,
when <span class="math notranslate nohighlight">\(g\)</span> is equal to
<span class="math notranslate nohighlight">\(g_{\mathrm{min}}\)</span>
(a very small value such as <span class="math notranslate nohighlight">\(10^{-12}\,\mho\)</span>, i.e., a resistance of
<span class="math notranslate nohighlight">\(10^{12}\,\Omega\)</span>), we get the solution for the original circuit since
the added resistances are as good as open circuits.</li>
</ul>
<a class="reference internal image-reference" href="_images/nr13.png"><img alt="gmin stepping" src="_images/nr13.png" style="width: 400px;" /></a>
<ul>
<li><p class="first"><strong>Source stepping</strong>:
In electronic circuits, there is a voltage supply (denoted typically
by <span class="math notranslate nohighlight">\(V_{CC}\)</span> in BJT circuits and by <span class="math notranslate nohighlight">\(V_{DD}\)</span> in FET circuits) which
“drives” the circuit. If this source voltage is made zero, all currents
and voltages would become zero. This
suggests that, with <span class="math notranslate nohighlight">\(V_{CC}\)</span> (or <span class="math notranslate nohighlight">\(V_{DD}\)</span>) equal to zero, the NR method
should have no trouble in converging to the solution with the
simple initial guess of zero currents and voltages. Next, we increase
<span class="math notranslate nohighlight">\(V_{CC}\)</span> by a small amount, say, <span class="math notranslate nohighlight">\(0.1\,{\textrm{V}}\)</span>.
Since this situation is not substantially different, we once again expect the
NR process to converge
easily. Continuing this procedure, we finally obtain the solution for the
actual source voltage, typically <span class="math notranslate nohighlight">\(5\,{\textrm{V}}\)</span> in BJT circuits.
Since the parameter being stepped is a source voltage, we can refer to this
procedure as “source stepping.”</p>
<p>A variation of the above approach is “source ramping” in which the source
voltage is ramped (in time) from <span class="math notranslate nohighlight">\(0\,{\textrm{V}}\)</span> to its final
value in a suitable time interval, taking the solution obtained at a given
time point as the initial guess for the next time point.</p>
</li>
</ul>
</div>
<div class="section" id="limiting-junction-voltages">
<span id="diode-limiting"></span><h3>Limiting junction voltages<a class="headerlink" href="#limiting-junction-voltages" title="Permalink to this headline">¶</a></h3>
<p>Semiconductor devices generally have one or more <span class="math notranslate nohighlight">\(p\)</span>-<span class="math notranslate nohighlight">\(n\)</span> junctions.
In the actual solution for the circuit under consideration, the voltage
across a junction is limited to about <span class="math notranslate nohighlight">\(0.8\,{\textrm{V}}\)</span> which corresponds to a
few Amps.
However, during the NR process, some of the junction voltages
can become larger than the values expected in the solution,
causing the current~– which is proportional to
<span class="math notranslate nohighlight">\(e^{V/V_T}\)</span> – to blow up. For example, with <span class="math notranslate nohighlight">\(V = 2\,{\textrm{V}}\)</span> and
<span class="math notranslate nohighlight">\(V_T = 26\,{\textrm{mV}}\)</span>,
<span class="math notranslate nohighlight">\(e^{V/V_T}\)</span> is of the order of <span class="math notranslate nohighlight">\(10^{33}\)</span>. When that happens, the NR method
comes to a grinding halt because of numerical overflow. It is important
therefore to limit the junction voltages in the NR process. The strategy
used in SPICE for this purpose is shown in the flow chart below.
The junction voltages in iterations <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\((i+1)\)</span> are denoted by
<span class="math notranslate nohighlight">\(V_{\mathrm{old}}\)</span> and
<span class="math notranslate nohighlight">\(V_{\mathrm{new}}\)</span>, respectively. The “critical voltage”
<span class="math notranslate nohighlight">\(V_{\mathrm{crit}}\)</span> in the flow chart is a fixed voltage at which
the exponential factor
<span class="math notranslate nohighlight">\(e^{V/V_T}\)</span> becomes impractically large.</p>
<a class="reference internal image-reference" href="_images/nr14.png"><img alt="limiting diode voltage" src="_images/nr14.png" style="width: 450px;" /></a>
</div>
<div class="section" id="changing-time-step">
<span id="change-delt"></span><h3>Changing time step<a class="headerlink" href="#changing-time-step" title="Permalink to this headline">¶</a></h3>
<p>In transient (or “dynamic”) simulation, the time axis is discretised,
and the circuit equations are solved at
discrete time points
<span class="math notranslate nohighlight">\(t_0\)</span>,
<span class="math notranslate nohighlight">\(t_1\)</span>,
<span class="math notranslate nohighlight">\(t_2\)</span>,
<span class="math notranslate nohighlight">\(\cdots\)</span>,
<span class="math notranslate nohighlight">\(t_n\)</span>,
<span class="math notranslate nohighlight">\(t_{n+1}\)</span>,
all the way up to the last time point of interest
<span class="math notranslate nohighlight">\(t_{\mathrm{end}}\)</span> (see figure). The solution at <span class="math notranslate nohighlight">\(t_n\)</span>
serves as the initial guess for the NR process at <span class="math notranslate nohighlight">\(t_{n+1}\)</span>.
If <span class="math notranslate nohighlight">\(t_{n+1}\)</span> is sufficiently close to <span class="math notranslate nohighlight">\(t_n\)</span>,
we expect the NR process at <span class="math notranslate nohighlight">\(t_{n+1}\)</span> to converge easily.
If we perform a fixed number of NR iterations and find that
the NR process has not converged, we can reduce the time step
<span class="math notranslate nohighlight">\(\Delta t = t_{n+1}-t_n\)</span>, i.e., bring
<span class="math notranslate nohighlight">\(t_{n+1}\)</span> closer to
<span class="math notranslate nohighlight">\(t_n\)</span>. In other words, we now look for
<span class="math notranslate nohighlight">\({\bf{x}}_{n+1}\)</span> which is closer to
<span class="math notranslate nohighlight">\({\bf{x}}_n\)</span>, and that improves the chances of convergence.</p>
<a class="reference internal image-reference" href="_images/nr15.png"><img alt="time axis" src="_images/nr15.png" style="width: 450px;" /></a>
</div>
</div>
<div class="section" id="nonlinear-circuits">
<span id="nr-circuits"></span><h2>Nonlinear circuits<a class="headerlink" href="#nonlinear-circuits" title="Permalink to this headline">¶</a></h2>
<p>In combination with the
<a class="reference internal" href="mna.html#mna"><span class="std std-ref">Modified Nodal Analysis</span></a> (MNA) approach
for assembling the circuit equations,
the NR method can be used to obtain the solution – currents and
voltages – for a nonlinear circuit. Consider the circuit shown below.</p>
<a class="reference internal image-reference" href="_images/nr17.png"><img alt="diode circuit" src="_images/nr17.png" style="width: 250px;" /></a>
<p>The diode current can be written using the Shockley equation as</p>
<div class="math notranslate nohighlight" id="equation-eq-nr-18">
<span class="eqno">(76)<a class="headerlink" href="#equation-eq-nr-18" title="Permalink to this equation">¶</a></span>\[I_D = I_s\left(e^{V_D/V_T}-1\right) =
I_s\left(e^{V_2/V_T}-1\right) \equiv I_D(V_2),\]</div>
<p>where <span class="math notranslate nohighlight">\(I_s\)</span> is the reverse saturation current of the diode (typically
of the order of pA for low-power diodes), and
<span class="math notranslate nohighlight">\(V_T = kT/q\)</span> is the thermal voltage (about <span class="math notranslate nohighlight">\(25\,{\textrm{mV}}\)</span> at room
temperature). Using the MNA approach,
we can assemble the circuit equations as</p>
<blockquote>
<div><div class="math notranslate nohighlight" id="equation-eq-nr-19">
<span class="eqno">(77)<a class="headerlink" href="#equation-eq-nr-19" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
{\textrm{KCL at B}}:~~ &amp;
G_1(V_1-V_2) + I_s &amp;= 0
\,, \\
{\textrm{KCL at C}}:~~ &amp;
G_1(V_2-V_1) +G_2V_2 + I_D(V_2) &amp;= 0
\,, \\
{\textrm{Voltage source equation}}:~~ &amp;
V_1-V_0 &amp;= 0
\,.
\end{align}\end{split}\]</div>
</div></blockquote>
<p>The above set of equations can be solved with the NR method, starting with
a suitable initial guess for the three variables, viz.,
<span class="math notranslate nohighlight">\(V_1\)</span>,
<span class="math notranslate nohighlight">\(V_2\)</span>, and
<span class="math notranslate nohighlight">\(I_s\)</span>.</p>
<p>In a similar manner, the NR scheme can be used for transient
simulation. More about that later, after we cover numerical
solution of ODEs.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">GSEIM</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="elements.html">Blocks and ports</a></li>
<li class="toctree-l1"><a class="reference internal" href="new_project.html">Creating a new project</a></li>
<li class="toctree-l1"><a class="reference internal" href="organisation.html">GSEIM Organisation</a></li>
<li class="toctree-l1"><a class="reference internal" href="templates.html">Element templates</a></li>
<li class="toctree-l1"><a class="reference internal" href="solve.html">Solve Blocks</a></li>
<li class="toctree-l1"><a class="reference internal" href="subckt.html">Subcircuits</a></li>
<li class="toctree-l1"><a class="reference internal" href="bedocs.html">Block Documents</a></li>
<li class="toctree-l1"><a class="reference internal" href="subckt_docs.html">Sub-circuit Documents</a></li>
<li class="toctree-l1"><a class="reference internal" href="proj_list.html">GSEIM projects</a></li>
<li class="toctree-l1"><a class="reference internal" href="mna.html">Modified nodal analysis</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Newton-Raphson method</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#single-equation">Single equation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#extension-to-set-of-equations">Extension to set of equations</a></li>
<li class="toctree-l2"><a class="reference internal" href="#convergence-criteria">Convergence criteria</a></li>
<li class="toctree-l2"><a class="reference internal" href="#graphical-interpretation-of-the-nr-process">Graphical interpretation of the NR process</a></li>
<li class="toctree-l2"><a class="reference internal" href="#convergence-issues">Convergence issues</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#damping-of-the-nr-iterations">Damping of the NR iterations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#parameter-stepping">Parameter stepping</a></li>
<li class="toctree-l3"><a class="reference internal" href="#limiting-junction-voltages">Limiting junction voltages</a></li>
<li class="toctree-l3"><a class="reference internal" href="#changing-time-step">Changing time step</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#nonlinear-circuits">Nonlinear circuits</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="numerical.html">Numerical methods for ODEs</a></li>
<li class="toctree-l1"><a class="reference internal" href="ssw.html">SSW computation</a></li>
<li class="toctree-l1"><a class="reference internal" href="startup.html">Start-up simulation</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="mna.html" title="previous chapter">Modified nodal analysis</a></li>
      <li>Next: <a href="numerical.html" title="next chapter">Numerical methods for ODEs</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2022, Mahesh Patil.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.8.5</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.8</a>
      
      |
      <a href="_sources/nr.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Numerical methods for ODEs &#8212; GSEIM 0.0.1 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="SSW computation" href="ssw.html" />
    <link rel="prev" title="Newton-Raphson method" href="nr.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="numerical-methods-for-odes">
<span id="numerical"></span><h1>Numerical methods for ODEs<a class="headerlink" href="#numerical-methods-for-odes" title="Permalink to this headline">¶</a></h1>
<p>In this section, we will look at numerical methods, in particular,
those employed in GSEIM. Although this section is not strictly
required for using GSEIM, it would help the user to develop a
better understanding of GSEIM (and to some extent other simulators
with similar capabilities). Most of the material presented in this
section is taken directly from the
<a class="reference external" href="https://www.ee.iitb.ac.in/~sequel/">SEQUEL manual</a>. The reader
may find it useful to check out the references listed there.</p>
<div class="section" id="explicit-methods">
<span id="explicit"></span><h2>Explicit methods<a class="headerlink" href="#explicit-methods" title="Permalink to this headline">¶</a></h2>
<p>Consider the ODE,</p>
<div class="math notranslate nohighlight" id="equation-neq-ode-1">
<span class="eqno">(78)<a class="headerlink" href="#equation-neq-ode-1" title="Permalink to this equation">¶</a></span>\[\displaystyle\frac{dx}{dt} = f(t,x),~~~x(t_0) = x_0.\]</div>
<p>In order to solve the ODE numerically, we <strong>discretise</strong> the time
axis from
<span class="math notranslate nohighlight">\(t_{\mathrm{start}}\)</span> to
<span class="math notranslate nohighlight">\(t_{\mathrm{end}}\)</span>
as shown below, and then replace the original ODE with an approximate
equation that depends on the numerical method being employed.</p>
<div class="figure" id="id2">
<span id="discretise"></span><a class="reference internal image-reference" href="_images/ode1.png"><img alt="time discretisation" src="_images/ode1.png" style="width: 500px;" /></a>
<p class="caption"><span class="caption-number">Fig. 2 </span><span class="caption-text">Time discretisation</span></p>
</div>
<p>We are interested in getting a numerical solution i.e., the <em>discrete</em>
values <span class="math notranslate nohighlight">\(x_1\)</span>, <span class="math notranslate nohighlight">\(x_2\)</span>, <span class="math notranslate nohighlight">\(\cdots\)</span>, corresponding to
<span class="math notranslate nohighlight">\(t_1\)</span>, <span class="math notranslate nohighlight">\(t_2\)</span>, etc. Throughout this section, we will denote
the exact solution by <span class="math notranslate nohighlight">\(x(t)\)</span>; e.g., <span class="math notranslate nohighlight">\(x(t_1)\)</span> means the exact solution
at <span class="math notranslate nohighlight">\(t_1\)</span>. On the other hand, we will denote the <em>numerical</em> solution at
<span class="math notranslate nohighlight">\(t_1\)</span> by <span class="math notranslate nohighlight">\(x_1\)</span>.</p>
<div class="section" id="forward-euler-method">
<h3>Forward Euler method<a class="headerlink" href="#forward-euler-method" title="Permalink to this headline">¶</a></h3>
<p>At <span class="math notranslate nohighlight">\(t = t_0\)</span>, we start with
<span class="math notranslate nohighlight">\(x = x_0\)</span> (the initial condition).
From Eq. <a class="reference internal" href="#equation-neq-ode-1">(78)</a>, we can compute the slope of <span class="math notranslate nohighlight">\(x(t)\)</span>
at <span class="math notranslate nohighlight">\(t_0\)</span> which is simply <span class="math notranslate nohighlight">\(f(t_0,x_0)\)</span>. In the Forward Euler (FE)
scheme, we make the approximation that this slope applies to the
entire interval <span class="math notranslate nohighlight">\((t_0,t_1)\)</span>, i.e., from the current time point to
the next time point. With this assumption, <span class="math notranslate nohighlight">\(x(t_1)\)</span> is given by
<span class="math notranslate nohighlight">\(x_1 = x_0+(t_1-t_0)\times f(t_0,x_0)\)</span>, as shown in the figure below.</p>
<a class="reference internal image-reference" href="_images/ode2.png"><img alt="forward euler method" src="_images/ode2.png" style="width: 330px;" /></a>
<p>Similarly, from <span class="math notranslate nohighlight">\(x_1\)</span>, we can get <span class="math notranslate nohighlight">\(x_2\)</span>, and
so on. In general, we have</p>
<div class="math notranslate nohighlight" id="equation-neq-ode-2">
<span class="eqno">(79)<a class="headerlink" href="#equation-neq-ode-2" title="Permalink to this equation">¶</a></span>\[ x_{n+1} = x_n + \Delta t_n f(t_n,x_n),\]</div>
<p>where <span class="math notranslate nohighlight">\(\Delta t_n = t_{n+1}-t_n\)</span>.
Let us apply the FE method to the ODE,</p>
<div class="math notranslate nohighlight" id="equation-neq-ode-3">
<span class="eqno">(80)<a class="headerlink" href="#equation-neq-ode-3" title="Permalink to this equation">¶</a></span>\[\displaystyle\frac{dx}{dt} = a\left(\sin \omega t -x\right),~~x(0)=0,\]</div>
<p>which has the analytical (exact) solution,</p>
<div class="math notranslate nohighlight" id="equation-neq-ode-4">
<span class="eqno">(81)<a class="headerlink" href="#equation-neq-ode-4" title="Permalink to this equation">¶</a></span>\[x(t) =
\displaystyle\frac{a\omega}{a^2+\omega ^2}\left(e^{-at}-\cos \omega t\right) +
\displaystyle\frac{a^2}{a^2+\omega ^2}\,\sin \omega t.\]</div>
<p>The following C program can be used to obtain the numerical solution
of Eq. <a class="reference internal" href="#equation-neq-ode-3">(80)</a> with the FE method.</p>
<div class="highlight-text notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25</pre></div></td><td class="code"><div class="highlight"><pre><span></span>#include&lt;stdio.h&gt;
#include&lt;math.h&gt;

int main()
{
  double t,t_start,t_end,h,x,x0,f;
  double a,w;
  FILE *fp;

  x0=0.0; t_start=0.0; t_end=5.0; h=0.05;
  a=1.0; w=5.0;

  fp=fopen(&quot;fe1.dat&quot;,&quot;w&quot;);

  t=t_start; x=x0;
  fprintf(fp,&quot;%13.6e %13.6e\n&quot;,t,x);

  while (t &lt;= t_end) {
    f = a*(sin(w*t)-x);
    x = x + h*f;
    t = t + h;
    fprintf(fp,&quot;%13.6e %13.6e\n&quot;,t,x);
  }
  fclose(fp);
}
</pre></div>
</td></tr></table></div>
<p>The numerical solution along with the analytical (exact) solution given by
Eq. :eq:neq_ode_4 are shown below.</p>
<a class="reference internal image-reference" href="_images/ode3a.png"><img alt="FE solution" src="_images/ode3a.png" style="width: 400px;" /></a>
<p>Note that the numerical solution appears to be continuous; however, in reality,
it consists of discrete points which are generally connected with line segments
serving as a “guide to the eye.” We notice some difference between
the two, but it can be made smaller by using a smaller step size <span class="math notranslate nohighlight">\(h\)</span>.
(Readers new to numerical analysis should try this out by running the program
with a smaller value of <span class="math notranslate nohighlight">\(h\)</span>, e.g., <span class="math notranslate nohighlight">\(h = 0.02\)</span>. In these matters,
there is no substitute for hands-on experience.)</p>
<p>In general, the accuracy of a numerical method for solving ODEs is described by
the <strong>order</strong> of the method which in turn depends on the <strong>Local Truncation Error</strong>
(LTE) for that method. The LTE is a measure of the <em>local</em> error (i.e., error
made in a single time step) and is defined as [Shampine, 1994],</p>
<div class="math notranslate nohighlight" id="equation-neq-ode-5">
<span class="eqno">(82)<a class="headerlink" href="#equation-neq-ode-5" title="Permalink to this equation">¶</a></span>\[{\textrm{LTE}} = x(t_{n+1})-x_{n+1},\]</div>
<p>where <span class="math notranslate nohighlight">\(x(t_{n+1})\)</span> is the exact solution at <span class="math notranslate nohighlight">\(t_{n+1}\)</span>, and
<span class="math notranslate nohighlight">\(u_{n+1}\)</span> is the solution obtained by the numerical method,
starting with the exact solution <span class="math notranslate nohighlight">\(x(t_n)\)</span> at <span class="math notranslate nohighlight">\(t = t_n\)</span>.
If our numerical method was perfect, <span class="math notranslate nohighlight">\(x_{n+1}\)</span> would be the same as
<span class="math notranslate nohighlight">\(x(t_{n+1})\)</span>, and the LTE would be zero.</p>
<p>Let us look at the LTE of the FE method for the test equation,</p>
<div class="math notranslate nohighlight" id="equation-neq-ode-6">
<span class="eqno">(83)<a class="headerlink" href="#equation-neq-ode-6" title="Permalink to this equation">¶</a></span>\[\displaystyle\frac{dx}{dt} = -\lambda x,~~~x(0)=1,~~\lambda &gt; 0,\]</div>
<p>with the exact solution</p>
<div class="math notranslate nohighlight" id="equation-neq-ode-7">
<span class="eqno">(84)<a class="headerlink" href="#equation-neq-ode-7" title="Permalink to this equation">¶</a></span>\[x = e^{-\lambda t}.\]</div>
<p>To compute the LTE, we take a specific <span class="math notranslate nohighlight">\(t_n\)</span>, say,
<span class="math notranslate nohighlight">\(t_n = t_0 = 0\)</span>, and compute
<span class="math notranslate nohighlight">\(x_{n+1}\)</span> (i.e., <span class="math notranslate nohighlight">\(x_1\)</span>) by performing one step of the FE method,
starting with <span class="math notranslate nohighlight">\(x_0 = 1\)</span>.
The exact solution at <span class="math notranslate nohighlight">\(t = t_{n+1} = h\)</span> is
<span class="math notranslate nohighlight">\(x(h) = e^{-\lambda h}\)</span>. The LTE is the difference between
<span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x(h)\)</span>.</p>
<p>The LTE (magnitude) as a function of time step <span class="math notranslate nohighlight">\(h\)</span> is shown in the
following figure. As <span class="math notranslate nohighlight">\(h\)</span> is reduced by a factor of 10 (from
<span class="math notranslate nohighlight">\(10^{-1}\)</span> to <span class="math notranslate nohighlight">\(10^{-2}\)</span>, for example), the LTE goes down by
two orders of magnitude. In other words, the LTE varies as <span class="math notranslate nohighlight">\(h^2\)</span>,
and therefore the FE method is said to be of order 1. In general, if
the <span class="math notranslate nohighlight">\({\textrm{LTE}}~\sim h^{k+1}\)</span> for a numerical method, then
it is said to be of order <span class="math notranslate nohighlight">\(k\)</span>.</p>
<div class="figure" id="id3">
<span id="lteferk4"></span><a class="reference internal image-reference" href="_images/ode4a.png"><img alt="_images/ode4a.png" src="_images/ode4a.png" style="width: 400px;" /></a>
<p class="caption"><span class="caption-number">Fig. 3 </span><span class="caption-text">LTE for FE and RK4</span></p>
</div>
</div>
<div class="section" id="runge-kutta-method-of-order-4">
<h3>Runge-Kutta method of order 4<a class="headerlink" href="#runge-kutta-method-of-order-4" title="Permalink to this headline">¶</a></h3>
<p>The Runge-Kutta method of order 4 (the <em>classic</em> form) is given by</p>
<div class="math notranslate nohighlight" id="equation-neq-ode-8">
<span class="eqno">(85)<a class="headerlink" href="#equation-neq-ode-8" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
 f_0 &amp;= f(t_n,x_n), \\
 f_1 &amp;= f\left(t_n+\displaystyle\frac{h}{2},x_n+\displaystyle\frac{h}{2}\,f_0\right), \\
 f_2 &amp;= f\left(t_n+\displaystyle\frac{h}{2},x_n+\displaystyle\frac{h}{2}\,f_1\right), \\
 f_3 &amp;= f\left(t_n+h,x_n+h\,f_2\right), \\
 x_{n+1} &amp;=
   x_n + h
  \left(
   \displaystyle\frac{1}{6}\,f_0 +
   \displaystyle\frac{1}{3}\,f_1 +
   \displaystyle\frac{1}{3}\,f_2 +
   \displaystyle\frac{1}{6}\,f_3
  \right).
\end{align}\end{split}\]</div>
<p>The order of the RK4 method can be made out from <a class="reference internal" href="#lteferk4"><span class="std std-ref">LTE for FE and RK4</span></a>:
if <span class="math notranslate nohighlight">\(h\)</span> is reduced by one order of magnitude, the LTE goes down by
five orders of magnitude (2.5 divisions, with each division
corresponding to two decades), and therefore the order is four.</p>
<p>Since the RK4 method is of a higher order, we expect it to be more
accurate than the FE method. Let us check that by comparing the
numerical solutions obtained with the two methods for the ODE
given by <a class="reference internal" href="#equation-neq-ode-3">(80)</a>. The following program can be used
for the RK4 method.</p>
<div class="highlight-text notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30</pre></div></td><td class="code"><div class="highlight"><pre><span></span>#include&lt;stdio.h&gt;
#include&lt;math.h&gt;

int main()
{
  double t,t_start,t_end,h,x,x0;
  double f0,f1,f2,f3;
  double a,w;
  FILE *fp;

  x0=0.0; t_start=0.0; t_end=5.0; h=0.05;
  a=1.0; w=5.0;

  fp=fopen(&quot;rk4.dat&quot;,&quot;w&quot;);

  t=t_start; x=x0;
  fprintf(fp,&quot;%13.6e %13.6e\n&quot;,t,x);

  while (t &lt;= t_end) {
    f0 = a*(sin(w*t)-x);
    f1 = a*(sin(w*(t+0.5*h))-(x+0.5*h*f0));
    f2 = a*(sin(w*(t+0.5*h))-(x+0.5*h*f1));
    f3 = a*(sin(w*(t+h))-(x+h*f2));

    x = x + (h/6.0)*(f0+f1+f1+f2+f2+f3);
    t = t + h;
    fprintf(fp,&quot;%13.6e %13.6e\n&quot;,t,x);
  }
  fclose(fp);
}
</pre></div>
</td></tr></table></div>
<p>The numerical solutions for <a class="reference internal" href="#equation-neq-ode-3">(80)</a> obtained with
the FE and RK4 methods (crosses and squares, respectively)
using a step size of <span class="math notranslate nohighlight">\(h = 0.05\)</span> are shown in the figure
below. The exact solution is also shown (red curve).
Clearly, the RK4 method is more accurate.</p>
<a class="reference internal image-reference" href="_images/ode5a.png"><img alt="FE and RK4 comparison" src="_images/ode5a.png" style="width: 600px;" /></a>
<p>Both FE and RK4 are <strong>explicit</strong> methods in the sense that
<span class="math notranslate nohighlight">\(x_{n+1}\)</span> can be computed simply by evaluating quantities based
on the past values of <span class="math notranslate nohighlight">\(x\)</span>
(see Eqs. <a class="reference internal" href="#equation-neq-ode-2">(79)</a> and <a class="reference internal" href="#equation-neq-ode-8">(85)</a>).
The RK4 method is more complicated as it involves computation
of the function values
<span class="math notranslate nohighlight">\(f_0\)</span>,
<span class="math notranslate nohighlight">\(f_1\)</span>,
<span class="math notranslate nohighlight">\(f_2\)</span>,
<span class="math notranslate nohighlight">\(f_3\)</span>,
but the entire computation can be completed in a step-by-step
manner. For example, the computation of <span class="math notranslate nohighlight">\(f_2\)</span> requires only
<span class="math notranslate nohighlight">\(x_n\)</span> and <span class="math notranslate nohighlight">\(f_1\)</span>, which are already available. The simplicity
of the computation is reflected in the programs we have seen.</p>
</div>
<div class="section" id="system-of-odes">
<span id="system-ode"></span><h3>System of ODEs<a class="headerlink" href="#system-of-odes" title="Permalink to this headline">¶</a></h3>
<p>The above methods (and other explicit methods) can be easily extended
to a set of ODEs of the form</p>
<div class="math notranslate nohighlight" id="equation-neq-ode-9">
<span class="eqno">(86)<a class="headerlink" href="#equation-neq-ode-9" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
 \displaystyle\frac{dx_1}{dt} &amp;= f_1(t,x_1,x_2,\cdots,x_N), \\
 \displaystyle\frac{dx_2}{dt} &amp;= f_2(t,x_1,x_2,\cdots,x_N), \\
 &amp; ~~~~\vdots \\
 \displaystyle\frac{dx_N}{dt} &amp;= f_N(t,x_1,x_2,\cdots,x_N),
\end{align}\end{split}\]</div>
<p>with the initial conditions at <span class="math notranslate nohighlight">\(t = t_0\)</span> specified as
<span class="math notranslate nohighlight">\(x_1(t_0) = x_1^{(0)}\)</span>,
<span class="math notranslate nohighlight">\(x_2(t_0) = x_2^{(0)}\)</span>, etc.
With vector notation, we can write the above set of equations as</p>
<div class="math notranslate nohighlight" id="equation-neq-ode-10">
<span class="eqno">(87)<a class="headerlink" href="#equation-neq-ode-10" title="Permalink to this equation">¶</a></span>\[\displaystyle\frac{d {\bf{x}}}{dt} = {\bf{f}}(t,{\bf{x}}),~~~{\bf{x}}(t_0) = {\bf{x}}^{(0)}.\]</div>
<p>The FE method for this set of ODEs can be written as</p>
<div class="math notranslate nohighlight" id="equation-neq-ode-11">
<span class="eqno">(88)<a class="headerlink" href="#equation-neq-ode-11" title="Permalink to this equation">¶</a></span>\[{\bf{x}}^{(n+1)} = {\bf{x}}^{(n)} + h\,{\bf{f}}(t_n,{\bf{x}}^{(n)}),\]</div>
<p>and the RK4 method as</p>
<div class="math notranslate nohighlight" id="equation-neq-ode-12">
<span class="eqno">(89)<a class="headerlink" href="#equation-neq-ode-12" title="Permalink to this equation">¶</a></span>\[\begin{split}{\bf{f}}_0
&amp;= {\bf{f}}(t_n,{\bf{x}}^{(n)}),
\\
{\bf{f}}_1
&amp;= {\bf{f}}(t_n+\displaystyle\frac{h}{2},{\bf{x}}^{(n)}+
  \displaystyle\frac{h}{2}\,{\bf{f}}_0),
\\
{\bf{f}}_2
&amp;= {\bf{f}}(t_n+\displaystyle\frac{h}{2},{\bf{x}}^{(n)}+
  \displaystyle\frac{h}{2}\,{\bf{f}}_1),
\\
{\bf{f}}_3
&amp;= {\bf{f}}(t_n+h,{\bf{x}}^{(n)}+h\,{\bf{f}}_2),
\\
{\bf{x}}^{(n+1)}
&amp;= {\bf{x}}^{(n)} + h
 \left(
  \displaystyle\frac{1}{6}\,{\bf{f}}_0 +
  \displaystyle\frac{1}{3}\,{\bf{f}}_1 +
  \displaystyle\frac{1}{3}\,{\bf{f}}_2 +
  \displaystyle\frac{1}{6}\,{\bf{f}}_3
 \right),\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\({\bf{x}}^{(n)}\)</span> denotes the solution vector at time <span class="math notranslate nohighlight">\(t_n\)</span>.
As in the single-equation case, the evaluations can be performed in a step-by-step
manner, enabling a straightforward implementation.</p>
<p>The simplicity of explicit methods makes them very attractive. Furthermore,
the implementation remains easy even if the functions <span class="math notranslate nohighlight">\(f_i\)</span> are nonlinear.
Let us illustrate this point with an example. Consider the system of
ODEs given by</p>
<div class="math notranslate nohighlight" id="equation-neq-ode-13">
<span class="eqno">(90)<a class="headerlink" href="#equation-neq-ode-13" title="Permalink to this equation">¶</a></span>\[\begin{split}\displaystyle\frac{dx_1}{dt}
&amp;= a_1\left(\sin \omega t -x_1\right)^3-a_2\left(x_1-x_2\right),
\\
\displaystyle\frac{dx_2}{dt}
&amp;= a_3\left(x_1-x_2\right),\end{split}\]</div>
<p>with the initial condition,
<span class="math notranslate nohighlight">\(x_1(0) = 0\)</span>,
<span class="math notranslate nohighlight">\(x_2(0) = 0\)</span>. If we use the FE method to solve the equations, we get</p>
<div class="math notranslate nohighlight" id="equation-neq-ode-14">
<span class="eqno">(91)<a class="headerlink" href="#equation-neq-ode-14" title="Permalink to this equation">¶</a></span>\[\begin{split}x_1^{(n+1)}
&amp;=
x_1^{(n)} +
h\left[a_1\left(\sin \omega t_n - x_1^{(n)}\right)^3-a_2\left(x_1^{(n)}-x_2^{(n)}\right)\right],
\\
x_2^{(n+1)}
&amp;=
x_2^{(n)} +
h\left[a_3\left(x_1^{(n)}-x_2^{(n)}\right)\right].\end{split}\]</div>
<p>The following program, which is a straightforward extension of our earlier
FE program, can be used to implement the above equations.</p>
<div class="highlight-text notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41</pre></div></td><td class="code"><div class="highlight"><pre><span></span>#include&lt;stdio.h&gt;
#include&lt;math.h&gt;

int main()
{
   double t,t_start,t_end,h;
   double x1,x2,f1,f2,b1;
   double w,a1,a2,a3,f_hz,pi;
   FILE *fp;

   f_hz = 5.0e3; // frequency = 5 kHz
   pi = acos(-1.0);
   w = 2.0*pi*f_hz;

   a1 = 5.0e3;
   a2 = 5.0e3;
   a3 = 5.0e3;

   t_start=0.0;
   t_end=5.0e-3;
   h=0.001e-3; // time step = 0.001 msec

   x1=0.0;
   x2=0.0;

   fp=fopen(&quot;fe3.dat&quot;,&quot;w&quot;);

   t=t_start;
   fprintf(fp,&quot;%13.6e %13.6e %13.6e\n&quot;,t,x1,x2);

   while (t &lt;= t_end) {
     b1 = sin(w*t)-x1;
     f1 = a1*b1*b1*b1 - a2*(x1-x2);
     f2 = a3*(x1-x2);
     x1 = x1 + h*f1;
     x2 = x2 + h*f2;
     t = t + h;
     fprintf(fp,&quot;%13.6e %13.6e %13.6e\n&quot;,t,x1,x2);
   }
   fclose(fp);
}
</pre></div>
</td></tr></table></div>
<p>As simple as that! The numerical solution is shown below.</p>
<a class="reference internal image-reference" href="_images/ode6a.png"><img alt="FE nonlinear example" src="_images/ode6a.png" style="width: 600px;" /></a>
</div>
<div class="section" id="adaptive-time-step">
<span id="ode-adaptive"></span><h3>Adaptive time step<a class="headerlink" href="#adaptive-time-step" title="Permalink to this headline">¶</a></h3>
<p>We have so far considered the time step <span class="math notranslate nohighlight">\(h\)</span> to be
constant. When the solution has regions of fast
and slow variations, it is much more efficient to
use adaptive (variable) time steps. When the solution
varies rapidly, small time steps are required to capture
the transients accurately; at other times, larger time steps can
be used.  In this way, the total number of time points – and thereby
the simulation time – can be made
much smaller than using a small, uniform time step.</p>
<p>In order to implement an adaptive time step scheme,
we need a mechanism to judge the accuracy of the numerical
solution. Ideally, we would like to
use the difference between the analytical solution
and the numerical solution, i.e., <span class="math notranslate nohighlight">\(|x(t_n)-x_n|\)</span>.
However, since the analytical solution is not available, we
need some other means of checking the accuracy. A commonly
used method is to estimate the local truncation error by
computing <span class="math notranslate nohighlight">\(x_{n+1}\)</span> with two numerical methods: one method of order
<span class="math notranslate nohighlight">\(p\)</span> and the other of order <span class="math notranslate nohighlight">\(p+1\)</span>. Let
<span class="math notranslate nohighlight">\({\textrm{LTE}}^{(p)}\)</span> and
<span class="math notranslate nohighlight">\({\textrm{LTE}}^{(p+1)}\)</span> denote the
local truncation errors in going from <span class="math notranslate nohighlight">\(t_n\)</span> to <span class="math notranslate nohighlight">\(t_{n+1}\)</span> for
the two methods, and let
<span class="math notranslate nohighlight">\(x_{n+1}\)</span> and <span class="math notranslate nohighlight">\(\tilde{x}_{n+1}\)</span> be the corresponding
numerical solutions. As we have seen,
<span class="math notranslate nohighlight">\({\textrm{LTE}}^{(p)}\)</span> and
<span class="math notranslate nohighlight">\({\textrm{LTE}}^{(p+1)}\)</span> are
<span class="math notranslate nohighlight">\(O(h^{p+1})\)</span> and
<span class="math notranslate nohighlight">\(O(h^{p+2})\)</span>, respectively. If we assume <span class="math notranslate nohighlight">\(x_n\)</span> to be equal to
the exact solution <span class="math notranslate nohighlight">\(x(t_n)\)</span>, we have</p>
<div class="math notranslate nohighlight" id="equation-neq-ode-adaptive-1">
<span class="eqno">(92)<a class="headerlink" href="#equation-neq-ode-adaptive-1" title="Permalink to this equation">¶</a></span>\[{\textrm{LTE}}^{(p)} = x(t_{n+1})-x_{n+1} ,\]</div>
<div class="math notranslate nohighlight" id="equation-neq-ode-adaptive-2">
<span class="eqno">(93)<a class="headerlink" href="#equation-neq-ode-adaptive-2" title="Permalink to this equation">¶</a></span>\[{\textrm{LTE}}^{(p+1)} = x(t_{n+1})-\tilde{x}_{n+1} .\]</div>
<p>Subtracting
Eq. <a class="reference internal" href="#equation-neq-ode-adaptive-2">(93)</a> from
Eq. <a class="reference internal" href="#equation-neq-ode-adaptive-1">(92)</a>, we get</p>
<div class="math notranslate nohighlight" id="equation-neq-ode-adaptive-3">
<span class="eqno">(94)<a class="headerlink" href="#equation-neq-ode-adaptive-3" title="Permalink to this equation">¶</a></span>\[{\textrm{LTE}}^{(p)}- {\textrm{LTE}}^{(p+1)}
= \tilde{x}_{n+1}- x_{n+1} \,.\]</div>
<p>Since
<span class="math notranslate nohighlight">\({\textrm{LTE}}^{(p+1)}\)</span> is expected to be much smaller than
<span class="math notranslate nohighlight">\({\textrm{LTE}}^{(p)}\)</span>, we can ignore it and obtain</p>
<div class="math notranslate nohighlight" id="equation-neq-ode-adaptive-4">
<span class="eqno">(95)<a class="headerlink" href="#equation-neq-ode-adaptive-4" title="Permalink to this equation">¶</a></span>\[{\textrm{LTE}}^{(p)} \approx \tilde{x}_{n+1}- x_{n+1} \,.\]</div>
<p>Having obtained an estimate for the LTE (denoted by
<span class="math notranslate nohighlight">\({\textrm{LTE}}^{\mathrm{est}}\)</span>) resulting from
a time step of <span class="math notranslate nohighlight">\(h_n = t_{n+1}-t_n\)</span>, we can now check if the solution
should be accepted or not. If <span class="math notranslate nohighlight">\({\textrm{LTE}}^{\mathrm{est}}\)</span>
is larger than the specified tolerance, we reject the current step and
try a smaller step.
If <span class="math notranslate nohighlight">\({\textrm{LTE}}^{\mathrm{est}}\)</span> is
smaller than the tolerance, we accept the solution obtained at
<span class="math notranslate nohighlight">\(t_{n+1}\)</span> (i.e., <span class="math notranslate nohighlight">\(x_{n+1}\)</span>). In this case, there is a
possibility that our current time step <span class="math notranslate nohighlight">\(h_n\)</span> is too conservative,
and we explore whether the next time step (i.e., <span class="math notranslate nohighlight">\(h_{n+1} = t_{n+2}-t_{n+1}\)</span>)
can be made larger.</p>
<p>A flow chart for implementing adaptive time steps based on the above ideas
is shown in the following figure.</p>
<a class="reference internal image-reference" href="_images/ode7.png"><img alt="adaptive step" src="_images/ode7.png" style="width: 500px;" /></a>
<p>The tolerance <span class="math notranslate nohighlight">\(\tau\)</span> specifies
the maximum value of the LTE per time step (i.e., <span class="math notranslate nohighlight">\({\textrm{LTE}}/h\)</span>) that is
acceptable. The method of order <span class="math notranslate nohighlight">\(p\)</span> is used for actually advancing the
solution, and the method of order <span class="math notranslate nohighlight">\(p+1\)</span> is used only to compute
<span class="math notranslate nohighlight">\({\textrm{LTE}}^{\mathrm{est}}\)</span> using Eq. <a class="reference internal" href="#equation-neq-ode-adaptive-4">(95)</a>.
Since <span class="math notranslate nohighlight">\({\textrm{LTE}}/h\)</span> is <span class="math notranslate nohighlight">\(O(h^p)\)</span>, we can write</p>
<div class="math notranslate nohighlight" id="equation-neq-ode-adaptive-5">
<span class="eqno">(96)<a class="headerlink" href="#equation-neq-ode-adaptive-5" title="Permalink to this equation">¶</a></span>\[\displaystyle\frac{{\rm LTE}^{(p)}}{h_n} =
\displaystyle\frac{|\tilde{x}_{n+1}-x_{n+1}|}{h_n} =
Kh_n^p.\]</div>
<p>Next, we compute the time step
(<span class="math notranslate nohighlight">\(\equiv \delta \times h_n\)</span>) which would result in
an LTE per time step equal to <span class="math notranslate nohighlight">\(\tau\)</span>, using</p>
<div class="math notranslate nohighlight" id="equation-neq-ode-adaptive-6">
<span class="eqno">(97)<a class="headerlink" href="#equation-neq-ode-adaptive-6" title="Permalink to this equation">¶</a></span>\[\tau = K(\delta h_n)^p.\]</div>
<p>From Eqs. <a class="reference internal" href="#equation-neq-ode-adaptive-5">(96)</a> and
<a class="reference internal" href="#equation-neq-ode-adaptive-6">(97)</a>, we obtain <span class="math notranslate nohighlight">\(\delta\)</span> as</p>
<div class="math notranslate nohighlight" id="equation-neq-ode-adaptive-7">
<span class="eqno">(98)<a class="headerlink" href="#equation-neq-ode-adaptive-7" title="Permalink to this equation">¶</a></span>\[\delta =
\left(
 \displaystyle\frac{\tau h_n}{|\tilde{x}_{n+1}-x_{n+1}|}
\right)^{1/p}.\]</div>
<p>If the current LTE per time step (in going from <span class="math notranslate nohighlight">\(t_n\)</span> to <span class="math notranslate nohighlight">\(t_{n+1}\)</span>)
is larger than <span class="math notranslate nohighlight">\(\tau\)</span> (i.e., <span class="math notranslate nohighlight">\(\delta &lt; 1\)</span>), we reject the
current time step and try a new time step <span class="math notranslate nohighlight">\(h_n \leftarrow \delta \times h_n\)</span>.
If it is smaller than <span class="math notranslate nohighlight">\(\tau\)</span>, we accept the current solution (<span class="math notranslate nohighlight">\(x_{n+1}\)</span>).
In this case, <span class="math notranslate nohighlight">\(\delta\)</span> is larger than one, and the next time step is
taken to be <span class="math notranslate nohighlight">\(h_{n+1} = \delta \times h_n\)</span>.</p>
<p>Since drastic changes in the time step are not suitable from the stability
perspective [Shampine, 1994], the value of <span class="math notranslate nohighlight">\(\delta\)</span> is generally
restricted to <span class="math notranslate nohighlight">\(\delta _{\mathrm{min}} \leq \delta \leq \delta _{\mathrm{max}}\)</span>,
as shown in the flow chart. Minimum and maximum limits are also imposed on
the step size (<span class="math notranslate nohighlight">\(h _{\mathrm{min}}\)</span> and
<span class="math notranslate nohighlight">\(h _{\mathrm{max}}\)</span> in the flow chart).</p>
<p>Different pairs of methods – of orders <span class="math notranslate nohighlight">\(p\)</span> and <span class="math notranslate nohighlight">\(p+1\)</span> – are available in
the literature for implementing the above scheme.
In the commonly used Runge-Kutta-Fehlberg (RKF45) pair,
which consists of an order-4 method and an order-5 method,
the LTE is estimated from [Burden, 2001]</p>
<div class="math notranslate nohighlight" id="equation-neq-rkf45-1">
<span class="eqno">(99)<a class="headerlink" href="#equation-neq-rkf45-1" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
 x_{n+1}
 &amp;=
 x_n + h_n\left(
 \displaystyle\frac{25}{216}\,f_0
 + \displaystyle\frac{1408}{2565}\,f_2
 + \displaystyle\frac{2197}{4104}\,f_3
 - \displaystyle\frac{1}{5}\,f_4
 \right),
 \\
  \tilde{x}_{n+1}
  &amp;=
  x_n + h_n\left(
 \displaystyle\frac{16}{135}\,f_0
 + \displaystyle\frac{6656}{12825}\,f_2
 + \displaystyle\frac{28561}{56430}\,f_3
 - \displaystyle\frac{9}{50}\,f_4
 + \displaystyle\frac{2}{55}\,f_5
 \right),
\end{align}\end{split}\]</div>
<p>where</p>
<div class="math notranslate nohighlight" id="equation-neq-rkf45-2">
<span class="eqno">(100)<a class="headerlink" href="#equation-neq-rkf45-2" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
 f_0 &amp;=
 f(t_n,x_n),
 \\
 f_1 &amp;=
 \left(
 t_n+\displaystyle\frac{h_n}{4},
 x_n
 +\displaystyle\frac{1}{4}\,f_0
 \right),
 \\
 f_2 &amp;=
 \left(
 t_n+
 \displaystyle\frac{3h_n}{8},
 x_n
 +\displaystyle\frac{3}{32}\,f_0
 +\displaystyle\frac{9}{32}\,f_1
 \right),
 \\
 f_3 &amp;=
 \left(
 t_n+
 \displaystyle\frac{12h_n}{13},
 x_n
 +\displaystyle\frac{1932}{2197}\,f_0
 -\displaystyle\frac{7200}{2197}\,f_1
 +\displaystyle\frac{7296}{2197}\,f_2
 \right),
 \\
 f_4 &amp;=
 \left(
 t_n+h_n,
 x_n
 +\displaystyle\frac{439}{216}\,f_0
 -8\,f_1
 +\displaystyle\frac{3680}{513}\,f_2
 -\displaystyle\frac{845}{4104}\,f_3
 \right),
 \\
 f_5 &amp;=
 \left(
 t_n+
 \displaystyle\frac{h_n}{2},
 x_n
 -\displaystyle\frac{8}{27}\,f_0
 +2\,f_1
 -\displaystyle\frac{3544}{2565}\,f_2
 +\displaystyle\frac{1859}{4104}\,f_3
 -\displaystyle\frac{11}{40}\,f_4
 \right).
\end{align}\end{split}\]</div>
<p>Note that the order-4 part of this method – the
computation of <span class="math notranslate nohighlight">\(x_{n+1}\)</span> in Eq. <a class="reference internal" href="#equation-neq-rkf45-1">(99)</a> –
is different from the classic RK4 method we have
seen earlier (Eq. <a class="reference internal" href="#equation-neq-ode-8">(85)</a>). The order-4 and
order-5 methods in the RKF45 scheme are designed
such that, with little extra computation (over the
order-4 method), we get the order-5 result
(<span class="math notranslate nohighlight">\(\tilde{x}_{n+1}\)</span> in Eq. <a class="reference internal" href="#equation-neq-rkf45-1">(99)</a>).</p>
<p>Let us illustrate the effectiveness of the RKF45 method
with an example. Consider the RC circuit shown below.</p>
<a class="reference internal image-reference" href="_images/ode9.png"><img alt="RC circuit" src="_images/ode9.png" style="width: 160px;" /></a>
<p>The behaviour of this circuit is described by the ODE,</p>
<div class="math notranslate nohighlight" id="equation-neq-rkf-rc-1">
<span class="eqno">(101)<a class="headerlink" href="#equation-neq-rkf-rc-1" title="Permalink to this equation">¶</a></span>\[\displaystyle\frac{dv_c}{dt} =
\displaystyle\frac{1}{\tau}\, (v_s-v_c),\]</div>
<p>where <span class="math notranslate nohighlight">\(\tau = RC\)</span>, and <span class="math notranslate nohighlight">\(v_s\)</span> is a known function
of time. In particular, we will consider <span class="math notranslate nohighlight">\(v_s(t)\)</span> to be a pulse
going from
<span class="math notranslate nohighlight">\(0\,{\textrm{V}}\)</span> to
<span class="math notranslate nohighlight">\(1\,{\textrm{V}}\)</span>
at <span class="math notranslate nohighlight">\(t_1 = 0.5\,{\textrm{sec}}\)</span>
with a rise time of
<span class="math notranslate nohighlight">\(0.05\,{\textrm{sec}}\)</span> and from
<span class="math notranslate nohighlight">\(1\,{\textrm{V}}\)</span> back to
<span class="math notranslate nohighlight">\(0\,{\textrm{V}}\)</span>
at <span class="math notranslate nohighlight">\(t_2 = 2\,{\textrm{sec}}\)</span>
with a fall time of
<span class="math notranslate nohighlight">\(0.05\,{\textrm{sec}}\)</span>.
The solution of Eq. <a class="reference internal" href="#equation-neq-rkf-rc-1">(101)</a>
obtained with the RKF45 method with a tolerance
<span class="math notranslate nohighlight">\(\tau = 10^{-4}\)</span> is shown below.
The other parameters are
<span class="math notranslate nohighlight">\(R = 1\,\Omega\)</span>,
<span class="math notranslate nohighlight">\(C = 1\,{\textrm{F}}\)</span>,
<span class="math notranslate nohighlight">\(\delta _{\mathrm{min}} = 0.2\)</span>,
<span class="math notranslate nohighlight">\(\delta _{\mathrm{max}} = 2\)</span>,
<span class="math notranslate nohighlight">\(h _{\mathrm{min}} = 10^{-5}\)</span>,
<span class="math notranslate nohighlight">\(h _{\mathrm{max}} = 0.5\)</span>.
As we expect, the time steps are small when the solution is changing
rapidly (i.e., near the pulse edges) and large
when it is changing slowly.</p>
<a class="reference internal image-reference" href="_images/ode8b.png"><img alt="RC circuit results" src="_images/ode8b.png" style="width: 600px;" /></a>
<p>The tolerance <span class="math notranslate nohighlight">\(\tau\)</span> needs to be chosen carefully. If it is
large, it may not give us a sufficiently accurate solution.
For example, as seen from the following figure, the solution obtained
with <span class="math notranslate nohighlight">\(\tau = 10^{-2}\)</span> (squares) differs significantly
from that obtained with <span class="math notranslate nohighlight">\(\tau = 10^{-4}\)</span> (crosses).</p>
<a class="reference internal image-reference" href="_images/ode8a.png"><img alt="RC circuit results" src="_images/ode8a.png" style="width: 600px;" /></a>
<p>On the other hand, reducing <span class="math notranslate nohighlight">\(\tau\)</span> beyond
<span class="math notranslate nohighlight">\(10^{-4}\)</span> does not change the solution any more, as seen
in the following figure showing results for
<span class="math notranslate nohighlight">\(\tau = 10^{-4}\)</span> (crosses) and
<span class="math notranslate nohighlight">\(\tau = 10^{-6}\)</span> (blue graph).
Note that we are being somewhat lax about terminology here – When we say
that “the solution does not change”, what we mean is, “I cannot make
out the difference, if any” which is often good enough in practice.
Looking through the microscope for a change in the fifth decimal
place is generally not called for in engineering problems.</p>
<a class="reference internal image-reference" href="_images/ode11a.png"><img alt="RC circuit results" src="_images/ode11a.png" style="width: 600px;" /></a>
<p>Although there is no perceptible difference in the results when
<span class="math notranslate nohighlight">\(\tau\)</span> is changed from
<span class="math notranslate nohighlight">\(10^{-4}\)</span> to
<span class="math notranslate nohighlight">\(10^{-6}\)</span>, the number of time points does increase.
The following figure shows the total number of time points
(<span class="math notranslate nohighlight">\(N_{\mathrm{total}}\)</span>) used by the RKF45 method in covering the
time interval from
<span class="math notranslate nohighlight">\(t_{\mathrm{start}}\)</span> to <span class="math notranslate nohighlight">\(t_{\mathrm{end}}\)</span> (i.e., 0 to 10 sec)
as a function of <span class="math notranslate nohighlight">\(\tau\)</span>.</p>
<a class="reference internal image-reference" href="_images/ode10a.png"><img alt="RC circuit results" src="_images/ode10a.png" style="width: 350px;" /></a>
<p>With a tighter
tolerance (smaller <span class="math notranslate nohighlight">\(\tau\)</span>), the number of time points to be simulated
goes up and so does the simulation time. For this specific problem,
we would not even notice the difference in the computation time,
but for larger problems (with a large number of variables or a large number
of time points or both), the difference could be substantial.</p>
<p>Sometimes, there is an “aesthetics” issue. What has aesthetics got
to do with science, we may ask. Consider the same RC circuit of
with a sinusoidal voltage source <span class="math notranslate nohighlight">\(V_m \sin \omega t\)</span>.
The results obtained with
<span class="math notranslate nohighlight">\(\tau = 10^{-5}\)</span> and
<span class="math notranslate nohighlight">\(\tau = 10^{-6}\)</span> are shown below.</p>
<a class="reference internal image-reference" href="_images/ode12a.png"><img alt="RC circuit sinusoid" src="_images/ode12a.png" style="width: 600px;" /></a>
<p>For <span class="math notranslate nohighlight">\(\tau = 10^{-5}\)</span>, the solution is accurate, i.e.,
the numerical solution agrees closely with the analytical solution.
However, it appears discontinuous because of the small number of
time points.
For <span class="math notranslate nohighlight">\(\tau = 10^{-6}\)</span>, the RKF45 method forces a larger number
of time points (smaller time steps) in order to meet the tolerance
requirement, and the solution now appears continuous, more in tune with
what we want to see.</p>
</div>
<div class="section" id="stability">
<span id="explicit-stability"></span><h3>Stability<a class="headerlink" href="#stability" title="Permalink to this headline">¶</a></h3>
<p>Apart from being sufficiently accurate,
a numerical method for solving ODEs must also be
<em>stable</em>, i.e., its “global error”
<span class="math notranslate nohighlight">\(|x(t_n)-x_n|\)</span> – where
<span class="math notranslate nohighlight">\(x(t_n)\)</span> and <span class="math notranslate nohighlight">\(x_n\)</span>
are the exact and numerical solutions,
respectively, at <span class="math notranslate nohighlight">\(t = t_n\)</span> – must remain bounded.</p>
<p>Broadly, we can talk of two types of stability.</p>
<ul class="simple">
<li>Stability for small <span class="math notranslate nohighlight">\(h\)</span>: Based on our discussion of
local truncation error, we would expect
that the accuracy of the numerical solution would
generally get better if we use smaller step sizes.
However, this is not true for all numerical methods.
We can have a method which is accurate to
a specified order in the local sense but is unstable
in the global sense (i.e., the numerical solution
“blows up” as time increases)
<em>even if</em> the time steps are small.
Such methods are of course of no use in circuit simulation,
and we will not discuss them here.</li>
<li>Stability for large <span class="math notranslate nohighlight">\(h\)</span>: All commonly used numerical methods
for solving ODEs (including the FE and RK4 methods we have
seen before) can be expected to work well when the step size
<span class="math notranslate nohighlight">\(h\)</span> is sufficiently small. When <span class="math notranslate nohighlight">\(h\)</span> is increased, we expect
the solution to be less accurate, but quite apart from that,
the solution may also become unstable, and that is a serious
concern. In the following, we will illustrate this point
with an example.</li>
</ul>
<p>Consider the RC circuit shown in the figure below.</p>
<div class="figure" id="id4">
<span id="tworc"></span><a class="reference internal image-reference" href="_images/ode16.png"><img alt="two-RC circuit" src="_images/ode16.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-number">Fig. 4 </span><span class="caption-text">RC circuit with two time constants</span></p>
</div>
<p>This circuit can be described by the ODEs,</p>
<div class="math notranslate nohighlight" id="equation-neq-tworc-ode-1">
<span class="eqno">(102)<a class="headerlink" href="#equation-neq-tworc-ode-1" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
 \displaystyle\frac{dV_1}{dt} &amp;=
 \displaystyle\frac{1}{R_1C_1}\,(V_s-V_1)-
 \displaystyle\frac{1}{R_2C_1}\,(V_1-V_2),
 \\
 \displaystyle\frac{dV_2}{dt} &amp;=
 \displaystyle\frac{1}{R_2C_2}\,(V_1-V_2).
\end{align}\end{split}\]</div>
<p>With a sinusoidal input,
<span class="math notranslate nohighlight">\(V_s = V_m\,\sin \omega t\)</span>,
we can use phasors
to estimate <span class="math notranslate nohighlight">\(V_1(t)\)</span> in steady state.
In particular, let
<span class="math notranslate nohighlight">\(R_1 = 1\,{\textrm{k}}\Omega\)</span>,
<span class="math notranslate nohighlight">\(R_2 = 2\,{\textrm{k}}\Omega\)</span>,
<span class="math notranslate nohighlight">\(C_1 = 540\,{\textrm{nF}}\)</span>,
<span class="math notranslate nohighlight">\(C_2 = 1\,{\textrm{mF}}\)</span>.
With these component values, and with a frequency
of <span class="math notranslate nohighlight">\({\textrm{50}}\,{\textrm{Hz}}\)</span>, we have
<span class="math notranslate nohighlight">\({\bf{Z}}_1 = -j5.9\,{\textrm{k}}\Omega\)</span>,
<span class="math notranslate nohighlight">\({\bf{Z}}_2 = -j3.2\,\Omega\)</span>.
Since
<span class="math notranslate nohighlight">\({\bf{Z}}_1\)</span> is relatively large, we can replace it with an
open circuit. Similarly, since
<span class="math notranslate nohighlight">\({\bf{Z}}_2\)</span> is small, we can replace it with a short circuit.
The approximate solution for
<span class="math notranslate nohighlight">\({\bf{V}}_1\)</span> is then simply</p>
<div class="math notranslate nohighlight" id="equation-neq-tworc-ode-2">
<span class="eqno">(103)<a class="headerlink" href="#equation-neq-tworc-ode-2" title="Permalink to this equation">¶</a></span>\[{\bf{V}}_1 \approx {\bf{V}}_s\,\displaystyle\frac{R_2}{R_1+R_2}.\]</div>
<p>The numerical solution obtained with the RK4 method with a time step
of $h = 1$,msec is shown below (the light
blue curve). Its amplitude and phase are in agreement with
Eq. <a class="reference internal" href="#equation-neq-tworc-ode-2">(103)</a>.</p>
<a class="reference internal image-reference" href="_images/ode15a.png"><img alt="two-RC RK result" src="_images/ode15a.png" style="width: 550px;" /></a>
<p>Do we expect any changes if <span class="math notranslate nohighlight">\(C_1\)</span> is changed from
<span class="math notranslate nohighlight">\(540\,{\textrm{nF}}\)</span> to <span class="math notranslate nohighlight">\(535\,{\textrm{nF}}\)</span>?
Nothing, really. This change is not going to significantly affect
the value of
<span class="math notranslate nohighlight">\({\bf{Z}}_1\)</span>, and we do not expect the solution to change
noticeably. However, as seen in the figure, the numerical solution
(obtained with the same RK4 method and with the same step size)
is dramatically different. It starts off being similar, but then
takes off toward infinity.</p>
<p>Why does the value of <span class="math notranslate nohighlight">\(C_1\)</span> make such a
dramatic difference? The answer has to do with stability of
the RK4 method. The following table gives the condition for stability
of a few explicit RK methods when applied to the ODE
<span class="math notranslate nohighlight">\(\displaystyle\frac{dx}{dt} = -\,\displaystyle\frac{x}{\tau}\)</span>.</p>
<table border="1" class="docutils">
<colgroup>
<col width="46%" />
<col width="54%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Method</th>
<th class="head">Maximum step size</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>RK-1 (same as FE)</td>
<td><span class="math notranslate nohighlight">\(2\,\tau\)</span></td>
</tr>
<tr class="row-odd"><td>RK-2</td>
<td><span class="math notranslate nohighlight">\(2\,\tau\)</span></td>
</tr>
<tr class="row-even"><td>RK-3</td>
<td><span class="math notranslate nohighlight">\(2.5\,\tau\)</span></td>
</tr>
<tr class="row-odd"><td>RK-4</td>
<td><span class="math notranslate nohighlight">\(2.8\,\tau\)</span></td>
</tr>
</tbody>
</table>
<p>We see that the RK4 method is unstable when the step size exceeds about
<span class="math notranslate nohighlight">\(2.8\, \tau\)</span> (<span class="math notranslate nohighlight">\(2.785\,\tau\)</span> to be more precise). If there
are several time constants governing the set of ODEs being solved,
this limit still holds with <span class="math notranslate nohighlight">\(\tau\)</span> replaced by the
<em>smallest</em> time constant.</p>
<p>Let us see the implications of the above limit in the context of our
RC example described by Eq. <a class="reference internal" href="#equation-neq-tworc-ode-1">(102)</a>.
This circuit has two time constants, and they vary with <span class="math notranslate nohighlight">\(C_1\)</span>
as shown below (with other component values held constant at
their previous values, viz.,
<span class="math notranslate nohighlight">\(R_1 = 1\,{\textrm{k}}\Omega\)</span>,
<span class="math notranslate nohighlight">\(R_2 = 2\,{\textrm{k}}\Omega\)</span>,
<span class="math notranslate nohighlight">\(C_2 = 1\,{\textrm{mF}}\)</span>).</p>
<a class="reference internal image-reference" href="_images/ode17a.png"><img alt="two-RC time constants" src="_images/ode17a.png" style="width: 550px;" /></a>
<p>The time constant marked <span class="math notranslate nohighlight">\(\tau _2\)</span> is the smaller of the two,
and it is
<span class="math notranslate nohighlight">\(0.356645\,{\textrm{msec}}\)</span> and
<span class="math notranslate nohighlight">\(0.359978\,{\textrm{msec}}\)</span>
for <span class="math notranslate nohighlight">\(C_1 = 535\,{\textrm{nF}}\)</span>
and <span class="math notranslate nohighlight">\(540\,{\textrm{nF}}\)</span>, respectively. For each of these,
the maximum time step <span class="math notranslate nohighlight">\(h_{\mathrm{max}}\)</span> to guarantee
stability of the RK4 method
can be obtained as
<span class="math notranslate nohighlight">\(2.785\,\tau _2\)</span>.
For <span class="math notranslate nohighlight">\(C_1 = 540\,{\textrm{nF}}\)</span>,
<span class="math notranslate nohighlight">\(h_{\mathrm{max}}\)</span> is
<span class="math notranslate nohighlight">\(1.0025\,{\textrm{msec}}\)</span>. The actual time step used for the numerical
solution <span class="math notranslate nohighlight">\((1\,{\textrm{msec}})\)</span> is smaller than this value, and the
solution is stable.
For <span class="math notranslate nohighlight">\(C_1 = 535\,{\textrm{nF}}\)</span>,
<span class="math notranslate nohighlight">\(h_{\mathrm{max}}\)</span> is
<span class="math notranslate nohighlight">\(0.9933\,{\textrm{msec}}\)</span>; the actual time step <span class="math notranslate nohighlight">\((1\,{\textrm{msec}})\)</span>
is now larger than this limit, thus leading to instability.</p>
<p>We can handle the instability problem by reducing the RK4 time step.
However, we generally do not have a good idea of the time constants
in a given circuit, and we would then need to carry out a cumbersome
trial-and-error process of choosing a time step, checking if it works,
reducing it if it does not, and so on. In these situations, the
adaptive (auto) time step methods –
such as the RKF45 method discussed in the
<a class="reference internal" href="#ode-adaptive"><span class="std std-ref">Adaptive time step</span></a> section –
can be used to advantage. When a given time step leads to
instability, the LTE also goes up, and the adaptive step method automatically
reduces the time step suitably <em>without</em> any intervention from the user. This is
indeed an attractive choice. Let us illustrate it with an example,
again the <a class="reference internal" href="#tworc"><span class="std std-ref">RC circuit with two time constants</span></a> but with different component values, viz.,
<span class="math notranslate nohighlight">\(R_1 = 1\,{\textrm{k}}\Omega\)</span>,
<span class="math notranslate nohighlight">\(R_2 = 1\,{\textrm{k}}\Omega\)</span>,
<span class="math notranslate nohighlight">\(C_1 = 1\,\mu{\textrm{F}}\)</span>,
<span class="math notranslate nohighlight">\(f = 1\,{\textrm{kHz}}\)</span>. As <span class="math notranslate nohighlight">\(C_2\)</span> is varied, the time
constants change (as seen earlier). When the RKF45 method is used to solve
the ODEs (Eq. <a class="reference internal" href="#equation-neq-tworc-ode-1">(102)</a>), the time step is automatically
adjusted to meet the specified tolerance requirement,
and a stable solution is obtained. As <span class="math notranslate nohighlight">\(C_2\)</span> is made smaller,
the smaller of the two time constants becomes
smaller, and the step sizes employed by the RKF45 algorithms also become
smaller, as shown in the following figure.
(The algorithmic parameters were
<span class="math notranslate nohighlight">\(\tau = 10^{-3}\)</span>,
<span class="math notranslate nohighlight">\(\delta _{\mathrm{min}} = 0.2\)</span>,
<span class="math notranslate nohighlight">\(\delta _{\mathrm{max}} = 2\)</span>,
<span class="math notranslate nohighlight">\(h _{\mathrm{min}} = 10^{-5}\)</span>,
<span class="math notranslate nohighlight">\(h _{\mathrm{max}} = 0.5\)</span>.)</p>
<a class="reference internal image-reference" href="_images/ode13a.png"><img alt="two-RC time step" src="_images/ode13a.png" style="width: 600px;" /></a>
<p>Sounds good, but there is a flip side.
Take for example <span class="math notranslate nohighlight">\(C_2 = 10^{-10}\,{\textrm{F}}\)</span>. The impedance <span class="math notranslate nohighlight">\({\bf{Z}}_2\)</span>
is then <span class="math notranslate nohighlight">\(-j64\,{\textrm{M}}\Omega\)</span> (at <span class="math notranslate nohighlight">\(f = 1\,{\textrm{kHz}}\)</span>), and it
is an open circuit for all practical purposes. The circuit reduces to a series
combination of <span class="math notranslate nohighlight">\(R_1\)</span> and <span class="math notranslate nohighlight">\(C_1\)</span>, and the solution is independent of
<span class="math notranslate nohighlight">\(C_2\)</span> (as long as it is small enough). We now have an unfortunate
situation in which <span class="math notranslate nohighlight">\(C_2\)</span> has no effect on the solution, yet it
forces small time steps because of stability considerations.</p>
<p>The above situation is an example of “stiff” circuits in which the time constants are
vastly different. We are often not interested in tracking the solution of a stiff
circuit on the scale of the smallest time constant, but because of the stability
constraints imposed by the numerical method, we are forced to use small time steps.
This is a drawback of explicit methods since, like the RK4 method, they
are <em>conditionally</em> stable.</p>
</div>
<div class="section" id="application-to-flow-graphs">
<span id="flowgraphs"></span><h3>Application to flow graphs<a class="headerlink" href="#application-to-flow-graphs" title="Permalink to this headline">¶</a></h3>
<p>In this section, we describe how GSEIM handles a flow graph when an explicit
numerical scheme (such as forwar Euler, RK4, RKF45) is used. We will consider
a simple flow graph (see figure) for the purpose of illustration. The signals
have been named as
<span class="math notranslate nohighlight">\(x_1\)</span>,
<span class="math notranslate nohighlight">\(x_2\)</span>, etc. and the blocks as
A, B, etc. The flow graph corresponds to the ODE:
<span class="math notranslate nohighlight">\(\displaystyle\frac{dx_6}{dt} = k_1x_1 + k_2x_2\)</span>,
where
<span class="math notranslate nohighlight">\(x_1 = A_1 \sin \omega _1 t\)</span>,
<span class="math notranslate nohighlight">\(x_2 = A_2 \sin \omega _2 t\)</span> (for example).</p>
<a class="reference internal image-reference" href="_images/flowgraph1.png"><img alt="flow graph example 1" src="_images/flowgraph1.png" style="width: 300px;" /></a>
<p>The flow graph has the following elements (blocks):</p>
<ul class="simple">
<li>signal sources (A, B)</li>
<li>scalar multipliers (C, D)</li>
<li>summer (E)</li>
<li>integrator (F)</li>
</ul>
<p>The integrator equation is
<span class="math notranslate nohighlight">\(x_6 = \displaystyle\int x_5dt\)</span>, or equivalently,
<span class="math notranslate nohighlight">\(\displaystyle\frac{dx_6}{dt} = x_5\)</span>. For simplicity,
we will use the forward Euler method to handle the time
derivative involved in the integrator equation. The remaining
elements can be described by algebraic equations, not involving
time derivatives. Denoting the numerical solution for <span class="math notranslate nohighlight">\(x_1\)</span> at
<span class="math notranslate nohighlight">\(t_n\)</span> as <span class="math notranslate nohighlight">\(x_1^n\)</span>, etc., we have the following equations
for the blocks.</p>
<ul class="simple">
<li>Block <strong>A</strong>: <span class="math notranslate nohighlight">\(x_1^{n+1} =  A_1 \,\sin \omega _1 t_{n+1}\)</span></li>
<li>Block <strong>B</strong>: <span class="math notranslate nohighlight">\(x_2^{n+1} =  A_2 \,\sin \omega _2 t_{n+1}\)</span></li>
<li>Block <strong>C</strong>: <span class="math notranslate nohighlight">\(x_3^{n+1} =  k_1 \,x_1^{n+1}\)</span></li>
<li>Block <strong>D</strong>: <span class="math notranslate nohighlight">\(x_4^{n+1} =  k_2 \,x_2^{n+1}\)</span></li>
<li>Block <strong>E</strong>: <span class="math notranslate nohighlight">\(x_5^{n+1} = x_3^{n+1} + x_4^{n+1}\)</span></li>
<li>Block <strong>F</strong>: <span class="math notranslate nohighlight">\(x_6^{n+1} = x_6^n + \Delta t \times x_5^n\)</span></li>
</ul>
<p>Simple enough. The question is: In what order should we visit these
equations? The order obviously depends on how the elements are
connected in the flow graph. For example, it makes sense to evaluate
the summer output
<span class="math notranslate nohighlight">\(x_5^{n+1}\)</span>
only after its inputs
<span class="math notranslate nohighlight">\(x_3^{n+1}\)</span>
<span class="math notranslate nohighlight">\(x_4^{n+1}\)</span>
have been updated.</p>
<p>The following observations would help in deciding on the order in
which the blocks should be processed.</p>
<ul class="simple">
<li>The integrator equation involves only the <em>past</em> values on the
right hand side; it can be evaluated independently of the other blocks,
i.e., we can process the integrator first and then the remaining
blocks, keeping in mind the flow graph connections.</li>
<li>Source elements do no have inputs. We can therefore process them
independently of the other blocks.</li>
<li>The remaining blocks should be processed in an order which ensures
that the inputs of a given block are updated before updating its
outputs.</li>
</ul>
<p>Using the above considerations, we can come up with the following
options for processing the blocks:</p>
<ul class="simple">
<li>F <span class="math notranslate nohighlight">\(\rightarrow\)</span> A <span class="math notranslate nohighlight">\(\rightarrow\)</span> B <span class="math notranslate nohighlight">\(\rightarrow\)</span> C <span class="math notranslate nohighlight">\(\rightarrow\)</span>
D <span class="math notranslate nohighlight">\(\rightarrow\)</span> E</li>
<li>F <span class="math notranslate nohighlight">\(\rightarrow\)</span> A <span class="math notranslate nohighlight">\(\rightarrow\)</span> B <span class="math notranslate nohighlight">\(\rightarrow\)</span> D <span class="math notranslate nohighlight">\(\rightarrow\)</span>
C <span class="math notranslate nohighlight">\(\rightarrow\)</span> E</li>
<li>F <span class="math notranslate nohighlight">\(\rightarrow\)</span> B <span class="math notranslate nohighlight">\(\rightarrow\)</span> A <span class="math notranslate nohighlight">\(\rightarrow\)</span> C <span class="math notranslate nohighlight">\(\rightarrow\)</span>
D <span class="math notranslate nohighlight">\(\rightarrow\)</span> E</li>
<li>F <span class="math notranslate nohighlight">\(\rightarrow\)</span> B <span class="math notranslate nohighlight">\(\rightarrow\)</span> A <span class="math notranslate nohighlight">\(\rightarrow\)</span> D <span class="math notranslate nohighlight">\(\rightarrow\)</span>
C <span class="math notranslate nohighlight">\(\rightarrow\)</span> E</li>
<li>F <span class="math notranslate nohighlight">\(\rightarrow\)</span> A <span class="math notranslate nohighlight">\(\rightarrow\)</span> C <span class="math notranslate nohighlight">\(\rightarrow\)</span> B <span class="math notranslate nohighlight">\(\rightarrow\)</span>
D <span class="math notranslate nohighlight">\(\rightarrow\)</span> E</li>
</ul>
<p>Note that all of these options are equivalent; the simulator can pick any
of them and use it in each time step.</p>
<p>With this background, we can also understand why
<a class="reference external" href="https://in.mathworks.com/products/simulink.html">Simulink</a>
processes blocks in a certain order. For example, here is the
Simulink block diagram for the same ODE, i.e.,
<span class="math notranslate nohighlight">\(\displaystyle\frac{dx_6}{dt} = k_1x_1 + k_2x_2\)</span>.</p>
<a class="reference internal image-reference" href="_images/order_sim_1.png"><img alt="simulink example 1" src="_images/order_sim_1.png" style="width: 500px;" /></a>
<p>Simulink uses red labels (see figure) to indicate the order in which
the blocks are processed. For example, for the integrator block, the
label is <code class="docutils literal notranslate"><span class="pre">0:0</span></code>, where the number after the colon indicates that it
is the first block to be processed. The second block to be processed
is the scope, but we can ignore it since it is used only for plotting.
After that, the top source is processed, and so on. The reader can verify
that the order corresponds to our last option, viz.,
F <span class="math notranslate nohighlight">\(\rightarrow\)</span> A <span class="math notranslate nohighlight">\(\rightarrow\)</span> C <span class="math notranslate nohighlight">\(\rightarrow\)</span>
B <span class="math notranslate nohighlight">\(\rightarrow\)</span> D <span class="math notranslate nohighlight">\(\rightarrow\)</span> E.</p>
<p>A slightly more complex Simulink block diagram along with the ordering
annotations is shown below. It is a good exercise to verify that it is
consistent with our remarks.</p>
<a class="reference internal image-reference" href="_images/order_sim_2.png"><img alt="simulink example 2" src="_images/order_sim_2.png" style="width: 650px;" /></a>
<p>An important point to note is the <em>simplicity</em>
of the simulation process when an explicit method is used.
Each of the above steps is straightforward – almost
trivial – to execute. In fact, even a nonlinear operation
(such as <span class="math notranslate nohighlight">\(x_6 = x_2\times x_4\)</span> in the block marked <code class="docutils literal notranslate"><span class="pre">0:5</span></code>)
requires no special consideration; it is just another
<em>evaluation</em>. In this respect, more complicated explicit
methods, such as the fourth-order Runge-Kutta method or the RKF45
method, are no different. They all involve <em>evaluation</em>
of a left-hand side using <em>known</em> numbers on the right-hand side.
This is in sharp contrast with
<a class="reference internal" href="#implicit"><span class="std std-ref">implicit methods</span></a>, as we shall see.</p>
</div>
<div class="section" id="algebraic-loops">
<span id="alg-loops"></span><h3>Algebraic loops<a class="headerlink" href="#algebraic-loops" title="Permalink to this headline">¶</a></h3>
<p>Consider the feedback loop shown in the figure.</p>
<a class="reference internal image-reference" href="_images/order_sim_3.png"><img alt="algebraic loop example" src="_images/order_sim_3.png" style="width: 250px;" /></a>
<p>We can write the following equation for this system:</p>
<div class="math notranslate nohighlight" id="equation-neq-alg-loop-1">
<span class="eqno">(104)<a class="headerlink" href="#equation-neq-alg-loop-1" title="Permalink to this equation">¶</a></span>\[x_3 = k_1\,x_2 = k_1\,(x_1-x_4) = k_1\,(x_1-k_2\,x_3)\,,\]</div>
<p>giving</p>
<div class="math notranslate nohighlight" id="equation-neq-alg-loop-2">
<span class="eqno">(105)<a class="headerlink" href="#equation-neq-alg-loop-2" title="Permalink to this equation">¶</a></span>\[x_3 = \displaystyle\frac{k_1}{1 + k_1 k_2}\,x_1\,.\]</div>
<p>This result is valid at all times, and we can obtain
<span class="math notranslate nohighlight">\(x_3(t_n)\)</span> in terms of
<span class="math notranslate nohighlight">\(x_1(t_n)\)</span> simply by evaluating the above formula.
Let us see if we can arrive at the same result by writing
out the equations for the respective blocks, as we did earlier.
Here are the equations we get:</p>
<div class="math notranslate nohighlight" id="equation-neq-alg-loop-3">
<span class="eqno">(106)<a class="headerlink" href="#equation-neq-alg-loop-3" title="Permalink to this equation">¶</a></span>\[x_2^{n+1} = x_1^{n+1} - x_4^{n+1} \,,\]</div>
<div class="math notranslate nohighlight" id="equation-neq-alg-loop-4">
<span class="eqno">(107)<a class="headerlink" href="#equation-neq-alg-loop-4" title="Permalink to this equation">¶</a></span>\[x_4^{n+1} = k_2\,x_3^{n+1} \,,\]</div>
<div class="math notranslate nohighlight" id="equation-neq-alg-loop-5">
<span class="eqno">(108)<a class="headerlink" href="#equation-neq-alg-loop-5" title="Permalink to this equation">¶</a></span>\[x_3^{n+1} = k_1\,x_2^{n+1} \,.\]</div>
<p>As before, we wish to evaluate these formulas <em>one at a time</em>,
but this leads to a conflict.
Eqs. <a class="reference internal" href="#equation-neq-alg-loop-3">(106)</a> to <a class="reference internal" href="#equation-neq-alg-loop-5">(108)</a>
are supposed to be valid <em>simultaneously</em>. For example,
the value of
<span class="math notranslate nohighlight">\(x_3^{n+1}\)</span> in
Eqs. <a class="reference internal" href="#equation-neq-alg-loop-4">(107)</a> and <a class="reference internal" href="#equation-neq-alg-loop-5">(108)</a>
is supposed to be the same. However, since
Eq. <a class="reference internal" href="#equation-neq-alg-loop-5">(108)</a> is evaluated <em>after</em>
Eq. <a class="reference internal" href="#equation-neq-alg-loop-4">(107)</a>, the two values are clearly different.
This type of conflict occurs when there is an <strong>algebraic loop</strong>
in the system, i.e., there is a loop in which the variables are
related through purely <em>algebraic</em> equations, not
involving time derivatives.</p>
<p>For an explicit method, an algebraic loop presents a roadblock.
We have the following options for a system with one or more
algebraic loops.</p>
<ul>
<li><p class="first">If possible, avoid algebraic loops. In the above example, this
would mean using
<span class="math notranslate nohighlight">\(x_3 = \displaystyle\frac{k_1}{1 + k_1 k_2}\,x_1\)</span>
directly.</p>
</li>
<li><p class="first">Insert a delay element to “break” an algebraic loop as shown in
the following figure.</p>
<a class="reference internal image-reference" href="_images/alg_loop_delay.png"><img alt="alg loop" src="_images/alg_loop_delay.png" style="width: 600px;" /></a>
<p>How does this help? The system equations can now be written as</p>
<div class="math notranslate nohighlight" id="equation-neq-alg-loop-7">
<span class="eqno">(109)<a class="headerlink" href="#equation-neq-alg-loop-7" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
 x_4^{n+1} &amp;= x_{3a}^n \,,\\
 x_2^{n+1} &amp;= x_1^{n+1} + x_4^{n+1} \,,\\
 x_3^{n+1} &amp;= k_1\,x_2^{n+1} \,,\\
 x_{3a}^{n+1} &amp;= k_2\,x_3^{n+1} \,.
\end{align}\end{split}\]</div>
<p>Note that <span class="math notranslate nohighlight">\(x_{3a}\)</span> in the first equation has a superscript <span class="math notranslate nohighlight">\(n\)</span>
because of the delay element.
We can see that the variables have now got “decoupled,” allowing a sequential
evaluation of the formulas, not requiring any iterative procedure. If the
delay is small compared to the time constants in the overall system, this
approach – however crude it may sound – gives acceptable accuracy although
it does change the original problem to some extent.</p>
</li>
<li><p class="first">Treat the integrator block(s) first (since their outputs depend
only on the past values), compute their outputs, and with those
held constant, solve the system of equations representing the
rest of the system. Let us illustrate this process with the
following example.</p>
<a class="reference internal image-reference" href="_images/flowgraph2.png"><img alt="flow graph example 2" src="_images/flowgraph2.png" style="width: 300px;" /></a>
<p>We first update the integrator output as</p>
<div class="math notranslate nohighlight">
\[x_2^{n+1} = x_2^n + h\,x_1^n\,,\]</div>
<p>where <span class="math notranslate nohighlight">\(h\)</span> is the time step. Now, we treat
<span class="math notranslate nohighlight">\(x_2^{n+1}\)</span> as a constant (say, <span class="math notranslate nohighlight">\(c\)</span>), and assemble the equations as
follows.</p>
<div class="math notranslate nohighlight" id="equation-neq-alg-loop-6">
<span class="eqno">(110)<a class="headerlink" href="#equation-neq-alg-loop-6" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
 x_2^{n+1} &amp;= c,\\
 x_1^{n+1} &amp;= A_1 \sin \omega \, t_{n+1},\\
 x_3^{n+1} &amp;= x_2^{n+1} + x_5^{n+1},\\
 x_4^{n+1} &amp;= k_1\,x_3^{n+1},\\
 x_5^{n+1} &amp;= k_2\,x_4^{n+1}.
\end{align}\end{split}\]</div>
<p>We have now obtained a system of equations which can be solved to get
updated values of
<span class="math notranslate nohighlight">\(x_1\)</span>,
<span class="math notranslate nohighlight">\(x_3\)</span>,
<span class="math notranslate nohighlight">\(x_4\)</span>,
<span class="math notranslate nohighlight">\(x_5\)</span>. Note that, in this example, the system of equations happens
to be linear, but in the general case, it could be nonlinear.</p>
</li>
<li><p class="first">Use an implicit method; in that case, algebraic loops do not need any special
treatment.</p>
</li>
</ul>
</div>
</div>
<div class="section" id="implicit-methods">
<span id="implicit"></span><h2>Implicit methods<a class="headerlink" href="#implicit-methods" title="Permalink to this headline">¶</a></h2>
<p>We have discussed so far a few explicit methods (in particular,
the Forward Euler (FE), Runge-Kutta order 4 (RK4), and
Runge-Kutta-Fehlberg (RKF45) methods) for solving the ODE
<span class="math notranslate nohighlight">\(\displaystyle\frac{dx}{dt} = f(t,x)\)</span>, with
<span class="math notranslate nohighlight">\(x(t_0) = x_0\)</span>.
We have also seen how the RKF45 method – a combination
of an RK4 method and an RK5 method – can be used to control
the time step in order to maintain a given accuracy (tolerance).
There are several other explicit methods available in the
literature (see [Lapidus, 1971], for example).
We can summarise the salient features of explicit methods as follows.</p>
<ul class="simple">
<li>Explicit methods are easy to implement since they only
involve <em>evaluation</em> of quantities rather than
<em>solution</em> of equations. The computational effort
per time point is therefore relatively small.</li>
<li>Explicit methods can be extended to a system of ODEs in
a straightforward manner. If there are <span class="math notranslate nohighlight">\(N\)</span> ODEs, the
computational effort would increase by a factor of <span class="math notranslate nohighlight">\(N\)</span>
as compared to solving a single ODE
(assuming all ODEs to be of similar complexity).</li>
<li>Explicit methods are conditionally stable – if the time
step is not sufficiently small (of the same order as the
smallest time constant), the numerical solution can
“blow up” (i.e., become unbounded).</li>
<li>In some problems, it may be difficult to know the various time
constants involved. In such cases, the “auto” (automatic or adaptive)
time step methods such as RKF45 are convenient. These methods can adjust
the time step automatically to ensure a certain
accuracy (in terms of the local truncation error estimate) and in
the process keep the numerical solution from blowing up.</li>
<li>Explicit methods are not suitable for stiff problems in which there
are vastly different time constants involved. This is because the
stability constraints imposed by an explicit method force small
time steps which may not be required from the accuracy perspective
at all.</li>
</ul>
<p>Given the above limitations, it is clear that an alternative
must be found for explicit methods. Implicit methods provide that
alternative.</p>
<div class="section" id="be-trz-and-bdf2-methods">
<span id="betrz"></span><h3>BE, TRZ, and BDF2 methods<a class="headerlink" href="#be-trz-and-bdf2-methods" title="Permalink to this headline">¶</a></h3>
<p>We will now look at the most commonly used implicit methods, viz.,
the backward Euler and trapezoidal methods. Systematic approaches are
available to derive these methods [Patil 2009]; here, we will present
a simplistic intuitive picture. Consider</p>
<div class="math notranslate nohighlight" id="equation-eq-impl-1">
<span class="eqno">(111)<a class="headerlink" href="#equation-eq-impl-1" title="Permalink to this equation">¶</a></span>\[\displaystyle\frac{dx}{dt} = f(t,x),~~~x(t_0) = x_0.\]</div>
<p>Suppose the solution <span class="math notranslate nohighlight">\(x(t)\)</span> is given by the curve shown in
the following figure.</p>
<div class="figure" id="id5">
<span id="figbetrz"></span><a class="reference internal image-reference" href="_images/impl1.png"><img alt="BE method" src="_images/impl1.png" style="width: 350px;" /></a>
<p class="caption"><span class="caption-number">Fig. 5 </span><span class="caption-text">Simple derivation of FE and BE formulas.</span></p>
</div>
<p>Consider the slope of the line joining the points
<span class="math notranslate nohighlight">\((t_n,x(t_n))\)</span> and
<span class="math notranslate nohighlight">\((t_{n+1},x(t_{n+1}))\)</span>, i.e.,
<span class="math notranslate nohighlight">\(m = \displaystyle\frac{x(t_{n+1})-x(t_n)}{h}\)</span>.
The forward Euler (FE) method results if we approximate the slope as</p>
<div class="math notranslate nohighlight" id="equation-eq-impl-2">
<span class="eqno">(112)<a class="headerlink" href="#equation-eq-impl-2" title="Permalink to this equation">¶</a></span>\[\displaystyle\frac{x(t_{n+1})-x(t_n)}{h}
\approx
\displaystyle\frac{x_{n+1}-x_n}{h}
\approx
\left. \displaystyle\frac{dx}{dt}\right|_{(t_n,x_n)}
= f(t_n,x_n),\]</div>
<p>where <span class="math notranslate nohighlight">\(x_n\)</span> and <span class="math notranslate nohighlight">\(x_{n+1}\)</span> are the numerical solutions at
<span class="math notranslate nohighlight">\(t_n\)</span> and <span class="math notranslate nohighlight">\(t_{n+1}\)</span>, respectively.</p>
<p>The backward Euler (BE) method results if the slope <span class="math notranslate nohighlight">\(m\)</span> is
equated to the slope at
<span class="math notranslate nohighlight">\((t_{n+1},x_{n+1})\)</span>, i.e.,
<span class="math notranslate nohighlight">\(\left. \displaystyle\frac{dx}{dt}\right|_{(t_{n+1},x_{n+1})}\)</span>
rather than
<span class="math notranslate nohighlight">\(\left. \displaystyle\frac{dx}{dt}\right|_{(t_n,x_n)}\)</span>.
In that case, we get</p>
<div class="math notranslate nohighlight" id="equation-eq-impl-3">
<span class="eqno">(113)<a class="headerlink" href="#equation-eq-impl-3" title="Permalink to this equation">¶</a></span>\[\displaystyle\frac{x(t_{n+1})-x(t_n)}{h}
\approx
\displaystyle\frac{x_{n+1}-x_n}{h}
\approx
\left. \displaystyle\frac{dx}{dt}\right|_{(t_{n+1},x_{n+1})}
= f(t_{n+1},x_{n+1}),\]</div>
<p>leading to</p>
<div class="math notranslate nohighlight" id="equation-eq-impl-4">
<span class="eqno">(114)<a class="headerlink" href="#equation-eq-impl-4" title="Permalink to this equation">¶</a></span>\[x_{n+1} = x_n + h
f(t_{n+1},x_{n+1}).\]</div>
<p>In case of the trapezoidal (TRZ) method, the slope <span class="math notranslate nohighlight">\(m\)</span>
is equated to the average of the two slopes (at
<span class="math notranslate nohighlight">\((t_{n},x_{n})\)</span> and
<span class="math notranslate nohighlight">\((t_{n+1},x_{n+1})\)</span>), i.e.,</p>
<div class="math notranslate nohighlight" id="equation-eq-impl-5">
<span class="eqno">(115)<a class="headerlink" href="#equation-eq-impl-5" title="Permalink to this equation">¶</a></span>\[\displaystyle\frac{x(t_{n+1})-x(t_n)}{h}
\approx
\displaystyle\frac{x_{n+1}-x_n}{h}
\approx
\displaystyle\frac{1}{2}
\left(
\left. \displaystyle\frac{dx}{dt}\right|_{(t_{n},x_{n})}+
\left. \displaystyle\frac{dx}{dt}\right|_{(t_{n+1},x_{n+1})}
\right)
=
\displaystyle\frac{1}{2}
\left(
f(t_{n},x_{n})+
f(t_{n+1},x_{n+1})
\right),\]</div>
<p>leading to</p>
<div class="math notranslate nohighlight" id="equation-eq-impl-6">
<span class="eqno">(116)<a class="headerlink" href="#equation-eq-impl-6" title="Permalink to this equation">¶</a></span>\[x_{n+1} = x_n + \displaystyle\frac{h}{2}
\left(
f(t_{n},x_{n})+
f(t_{n+1},x_{n+1})
\right).\]</div>
<p>Note that we have shown the time steps to be uniform in
<a class="reference internal" href="#figbetrz"><span class="std std-numref">Fig. 5</span></a>, but the above equations can also be
used for non-uniform time steps by replacing <span class="math notranslate nohighlight">\(h\)</span> with
<span class="math notranslate nohighlight">\(h_n \equiv t_{n+1}-t_n\)</span>.</p>
<p>The BE and TRZ methods are <em>implicit</em> in nature since
<span class="math notranslate nohighlight">\(x_{n+1}\)</span> is involved in the right-hand sides of
Eqs. <a class="reference internal" href="#equation-eq-impl-4">(114)</a> and <a class="reference internal" href="#equation-eq-impl-6">(116)</a>. In other words,
<span class="math notranslate nohighlight">\(x_{n+1}\)</span> cannot be simply <em>evaluated</em> in terms of known
quantities (except in some special cases such as
<span class="math notranslate nohighlight">\((a)\,f(t_{n+1},x_{n+1})\)</span> is linear in <span class="math notranslate nohighlight">\(x_{n+1}\)</span>,
<span class="math notranslate nohighlight">\((b)\,f(t_{n+1},x_{n+1})\)</span> does not involve <span class="math notranslate nohighlight">\(x_{n+1}\)</span> at all,
e.g., <span class="math notranslate nohighlight">\(f(t,x) = \cos \omega t\)</span>).</p>
<p>Instead, it needs to be obtained by <em>solving</em>
Eq. <a class="reference internal" href="#equation-eq-impl-4">(114)</a> or Eq. <a class="reference internal" href="#equation-eq-impl-6">(116)</a>.
As an example, consider</p>
<div class="math notranslate nohighlight" id="equation-eq-impl-7">
<span class="eqno">(117)<a class="headerlink" href="#equation-eq-impl-7" title="Permalink to this equation">¶</a></span>\[\displaystyle\frac{dx}{dt} \,\equiv\, f(t,x) \,=\, \cos x,~~
x(0) = 0.\]</div>
<p>The FE and BE methods give the discretised equations,</p>
<div class="math notranslate nohighlight" id="equation-eq-impl-8">
<span class="eqno">(118)<a class="headerlink" href="#equation-eq-impl-8" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
 {\textrm{FE :}}~
 &amp;
 x_{n+1} = x_{n} + h\,\cos\,(x_n),
 \\
 {\textrm{BE :}}~
 &amp;
 x_{n+1} = x_{n} + h\,\cos\,(x_{n+1}).
\end{align}\end{split}\]</div>
<p>There is a fundamental difference between the two equations
in terms of computational effort. If we use the FE method,
<span class="math notranslate nohighlight">\(x_{n+1}\)</span> can be obtained by simply evaluating the right-hand
side (since <span class="math notranslate nohighlight">\(x_n\)</span> is known). With the BE method, the task is far more complex because
the presence of
<span class="math notranslate nohighlight">\(x_{n+1}\)</span> on the RHS has made the equation nonlinear, thus requiring
an iterative solution process.
If we use the NR method, for example,
then each iteration will involve evaluation of the function,
its derivative, and the correction. Clearly, the work involved per
time point is much more when the BE method is used.
The following C program shows the implementation of the FE and BE
methods for solving Eq. <a class="reference internal" href="#equation-eq-impl-7">(117)</a>.</p>
<div class="highlight-text notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58</pre></div></td><td class="code"><div class="highlight"><pre><span></span>#include&lt;stdio.h&gt;
#include&lt;stdlib.h&gt;
#include&lt;math.h&gt;

int main()
{
   double t,x,f,t_start,t_end,h;
   double x_old;
   double f_nr,dfdx_nr,delx_nr;
   int i_nr,nmax_nr=10;
   FILE *fp;

   t_start = 0.0;
   t_end = 8.0;
   h = 0.05;

// Forward Euler:
   fp=fopen(&quot;fe.dat&quot;,&quot;w&quot;);

   t=t_start;
   x = 0.0; // initial condition
   fprintf(fp,&quot;%13.6e %13.6e\n&quot;,t,x);

   while (t &lt;= t_end) {
     f = cos(x);
     x = x + h*f;
     t = t + h;
     fprintf(fp,&quot;%13.6e %13.6e\n&quot;,t,x);
   }
   fclose(fp);

// Backward Euler:
   fp=fopen(&quot;be.dat&quot;,&quot;w&quot;);

   t=t_start;
   x = 0.0; // initial condition
   x_old = x;
   fprintf(fp,&quot;%13.6e %13.6e\n&quot;,t,x);

   while (t &lt;= t_end) {
//   Newton-Raphson loop
     for (i_nr=0; i_nr &lt; (nmax_nr+1); i_nr++) {
       if (i_nr == nmax_nr) {
         printf(&quot;N-R did not converge.\n&quot;);
         exit(0);
       }
       f_nr = x - h*cos(x) - x_old;
       if (fabs(f_nr) &lt; 1.0e-8) break;
       dfdx_nr = 1.0 + h*sin(x);
       delx_nr = -f_nr/dfdx_nr;
       x = x + delx_nr;
     }
     t = t + h;
     fprintf(fp,&quot;%13.6e %13.6e\n&quot;,t,x);
     x_old = x;
   }
   fclose(fp);
}
</pre></div>
</td></tr></table></div>
<p>The results are shown in the following figure for
a step size of <span class="math notranslate nohighlight">\(h = 0.05\)</span>.</p>
<a class="reference internal image-reference" href="_images/impl3a.png"><img alt="FE-BE results" src="_images/impl3a.png" style="width: 400px;" /></a>
<p>The BE and TRZ methods can be extended to solve a set of
ODEs (see Eqs. <a class="reference internal" href="#equation-neq-ode-9">(86)</a>, <a class="reference internal" href="#equation-neq-ode-10">(87)</a>):</p>
<div class="math notranslate nohighlight" id="equation-eq-impl-9">
<span class="eqno">(119)<a class="headerlink" href="#equation-eq-impl-9" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
{\textrm{BE:}}~
&amp;
{\bf{x}}^{(n+1)} = {\bf{x}}^{(n)} + h\,{\bf{f}}(t_{n+1},{\bf{x}}^{(n+1)}),
\\
{\textrm{TRZ:}}~
&amp;
{\bf{x}}^{(n+1)} = {\bf{x}}^{(n)} + \displaystyle\frac{h}{2}
\left(
{\bf{f}}(t_{n},{\bf{x}}^{(n)})+
{\bf{f}}(t_{n+1},{\bf{x}}^{(n+1)})
\right),
\end{align}\end{split}\]</div>
<p>where
<span class="math notranslate nohighlight">\({\bf{x}}^{(n)}\)</span> stands for the numerical solution at <span class="math notranslate nohighlight">\(t_n\)</span>, and so on.
As an illustration, let us consider the set of two ODEs
seen earlier (Eq. <a class="reference internal" href="#equation-neq-ode-13">(90)</a>) and reproduced here:</p>
<div class="math notranslate nohighlight" id="equation-eq-impl-10">
<span class="eqno">(120)<a class="headerlink" href="#equation-eq-impl-10" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
\displaystyle\frac{dx_1}{dt}
&amp;= a_1\left(\sin \omega t -x_1\right)^3-a_2\left(x_1-x_2\right),
\\
\displaystyle\frac{dx_2}{dt}
&amp;= a_3\left(x_1-x_2\right),
\end{align}\end{split}\]</div>
<p>with the initial condition,
<span class="math notranslate nohighlight">\(x_1(0) = 0\)</span>,
<span class="math notranslate nohighlight">\(x_2(0) = 0\)</span>.
The BE equations are given by</p>
<div class="math notranslate nohighlight" id="equation-eq-impl-11">
<span class="eqno">(121)<a class="headerlink" href="#equation-eq-impl-11" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
x_1^{(n+1)}
&amp;=
x_1^{(n)} +
h\left[a_1\left(\sin \omega t_{n+1} - x_1^{(n+1)}\right)^3-a_2\left(x_1^{(n+1)}-x_2^{(n+1)}\right)\right],
\\
x_2^{(n+1)}
&amp;=
x_2^{(n)} +
h\left[a_3\left(x_1^{(n+1)}-x_2^{(n+1)}\right)\right].
\end{align}\end{split}\]</div>
<p>We now have a set of nonlinear equations which must be solved
at each time point. The NR method is commonly used for this
purpose, and it entails computation of the Jacobian matrix and
the function vector, and solution of the Jacobian equation
(of the form <span class="math notranslate nohighlight">\({\bf{A}}{\bf{x}} = {\bf{b}}\)</span>) in each
iteration of the NR loop. As <span class="math notranslate nohighlight">\(N\)</span> (the number of ODEs) increases, the computational
cost of solving the Jacobian equations increases superlinearly
(<span class="math notranslate nohighlight">\(O(N^3)\)</span> for a dense matrix). On the other hand, with an explicit method,
we do not require to solve a system of equations, and the computational
effort can be expected to grow linearly with <span class="math notranslate nohighlight">\(N\)</span> (see the FE equations given by
Eq. <a class="reference internal" href="#equation-neq-ode-14">(91)</a>, for example). With respect to computational effort,
explicit methods are therefore clearly superior to implicit methods
<em>if</em> the number of time points to be simulated is the same in
both cases. That is a big if, as we will soon discover.</p>
<p>Another implicit method commonly used in circuit simulation is the
Backward Differentiation Formula of order 2 (BDF2), also known as
Gear’s method of order 2. It is given by</p>
<div class="math notranslate nohighlight" id="equation-eq-bdf2">
<span class="eqno">(122)<a class="headerlink" href="#equation-eq-bdf2" title="Permalink to this equation">¶</a></span>\[\displaystyle\frac{3}{2}\,x_{n+1}
-2\,x_n
+\displaystyle\frac{1}{2}\,x_{n-1}
=h\,f(t_{n+1},x_{n+1}).\]</div>
<p>Note that the BDF2 method involves <span class="math notranslate nohighlight">\(x_{n-1}\)</span> (in addition to
<span class="math notranslate nohighlight">\(x_{n+1}\)</span> and <span class="math notranslate nohighlight">\(x_n\)</span>), i.e., the numerical solution at
<span class="math notranslate nohighlight">\(t_{n-1}\)</span>. In deriving Eq. <a class="reference internal" href="#equation-eq-bdf2">(122)</a>, the time step is
assumed to be uniform, i.e.,
<span class="math notranslate nohighlight">\(t_{n+1}-t_n = t_n -t_{n-1} = h\)</span>; however,
it is possible to extend the BDF2 formula to the case of non-uniform
time steps [McCalla, 1987]. With the BDF2 method (methods involving multiple
steps in general), starting is an issue since
at the very beginning (<span class="math notranslate nohighlight">\(t = t_0\)</span>), the solution is available
only at one time point, <span class="math notranslate nohighlight">\(x(t_0)\)</span>. In practice, a single-step method such as the BE method
is used to first go from <span class="math notranslate nohighlight">\(t_0\)</span> to <span class="math notranslate nohighlight">\(t_1\)</span>.
The BDF2 method can then be used to compute
<span class="math notranslate nohighlight">\(x_2\)</span> from <span class="math notranslate nohighlight">\(x_0\)</span> and <span class="math notranslate nohighlight">\(x_1\)</span>,
<span class="math notranslate nohighlight">\(x_3\)</span> from <span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x_2\)</span>, and so on.</p>
</div>
<div class="section" id="implicit-stability">
<span id="id1"></span><h3>Stability<a class="headerlink" href="#implicit-stability" title="Permalink to this headline">¶</a></h3>
<p>As we have seen in the <a class="reference internal" href="#explicit-stability"><span class="std std-ref">Stability</span></a> section, the explicit methods
we have discussed, viz., FE and RK4, are conditionally stable. This
puts an upper limit <span class="math notranslate nohighlight">\(h_{\mathrm{max}}\)</span> on the step size while
solving the test equation,</p>
<div class="math notranslate nohighlight" id="equation-eq-impl-12">
<span class="eqno">(123)<a class="headerlink" href="#equation-eq-impl-12" title="Permalink to this equation">¶</a></span>\[\displaystyle\frac{dx}{dt} = -\,\displaystyle\frac{t}{\tau},~~x(0)=1.\]</div>
<p>For the FE method,
<span class="math notranslate nohighlight">\(h_{\mathrm{max}}\)</span> is <span class="math notranslate nohighlight">\(2\,\tau\)</span>, and for the RK4 method, it is <span class="math notranslate nohighlight">\(2.8\,\tau\)</span>.
Other explicit methods are also conditionally stable.</p>
<p>The FE method is a member of the
Adams-Bashforth (AB) family of explicit linear multi-step methods.
The regions of stability of the
AB methods with respect to Eq. <a class="reference internal" href="#equation-eq-impl-12">(123)</a> are shown in
<a class="reference internal" href="#stability-ab-am"><span class="std std-numref">Fig. 6</span></a> (a).
For the AB1 (FE) method, we require
<span class="math notranslate nohighlight">\(h/\tau &lt; 2\)</span>, as we have already seen. As the order increases,
the AB methods become more accurate, but the region of stability shrinks.</p>
<div class="figure" id="id6">
<span id="stability-ab-am"></span><a class="reference internal image-reference" href="_images/impl2.png"><img alt="FE-BE results" src="_images/impl2.png" style="width: 650px;" /></a>
<p class="caption"><span class="caption-number">Fig. 6 </span><span class="caption-text">Regions of stability for A-B and A-M methods.</span></p>
</div>
<p>The BE and TRZ methods
belong to the Adams-Moulton (AM) family of implicit linear
multi-step methods. The BE method
is of order 1 while the TRZ method is of order 2.
The stability properties of the AM methods
with respect to Eq. <a class="reference internal" href="#equation-eq-impl-12">(123)</a> are shown in
<a class="reference internal" href="#stability-ab-am"><span class="std std-numref">Fig. 6</span></a> (b).
The BE and TRZ methods are
<em>unconditionally</em> stable while higher-order AM methods
have finite regions of stability which shrink as the order
increases. (Note: The BDF2 formula given by Eq. <a class="reference internal" href="#equation-eq-bdf2">(122)</a>
is also unconditionally stable, see [Patil, 2009]).</p>
<p>The unconditional stability of the BE and TRZ methods
allows us to break free from the stability
constraints which arise when an explicit method is used for a stiff circuit
(see <a class="reference internal" href="#explicit-stability"><span class="std std-ref">Stability</span></a>). This is a <em>huge</em> benefit; it means
that, if we use the BE or TRZ method, the only restriction on the time
step comes from accuracy of the numerical solution and not from stability.
For example, let us re-visit the stiff circuit shown in the following figure with
<span class="math notranslate nohighlight">\(V_m = 1\,{\textrm{V}}\)</span>,
<span class="math notranslate nohighlight">\(f = 1\,{\textrm{kHz}}\)</span>. The time step is <span class="math notranslate nohighlight">\(h = 0.02\,{\textrm{msec}}\)</span>.
We recall that, for this circuit, the RKF45 method was forced to
use very small time steps – of the order of nanoseconds –
because of stability considerations. The BE method is
not constrained by stability issues, and therefore a much larger time
step (<span class="math notranslate nohighlight">\(h = 0.02\,{\textrm{msec}}\)</span>) can be used
to obtain the numerical solution, as shown in the figure.</p>
<div class="figure" id="id7">
<a class="reference internal image-reference" href="_images/ode18a.png"><img alt="stiff circuit and BE results" src="_images/ode18a.png" style="width: 650px;" /></a>
<p class="caption"><span class="caption-number">Fig. 7 </span><span class="caption-text">Stiff circuit example</span></p>
</div>
<p>As another example, consider the half-wave rectifier circuit
shown below.</p>
<a class="reference internal image-reference" href="_images/impl4_cct.png"><img alt="half-wave rectifier" src="_images/impl4_cct.png" style="width: 200px;" /></a>
<p>The diode is represented with the
<span class="math notranslate nohighlight">\(R_{\mathrm{on}}\)</span>/<span class="math notranslate nohighlight">\(R_{\mathrm{off}}\)</span> model, with a turn-on voltage
equal to <span class="math notranslate nohighlight">\(0\,{\textrm{V}}\)</span> and <span class="math notranslate nohighlight">\(R_{\mathrm{off}} = 1\,{\textrm{M}}\Omega\)</span>.
The other parameters are
<span class="math notranslate nohighlight">\(V_m = 1\,{\textrm{V}}\)</span>,
<span class="math notranslate nohighlight">\(f = 50\,{\textrm{Hz}}\)</span>, <span class="math notranslate nohighlight">\(R = 500\,\Omega\)</span>,
<span class="math notranslate nohighlight">\(C = 600\,\mu {\textrm{F}}\)</span>.</p>
<p>The circuit behaviour is described by the ODE,</p>
<div class="math notranslate nohighlight" id="equation-eq-impl-13">
<span class="eqno">(124)<a class="headerlink" href="#equation-eq-impl-13" title="Permalink to this equation">¶</a></span>\[\displaystyle\frac{dV_o}{dt} =
\displaystyle\frac{1}{C}\left[
 \displaystyle\frac{V_s-V_o}{R_D}
-\displaystyle\frac{V_o}{R}
\right],\]</div>
<p>where <span class="math notranslate nohighlight">\(R_D\)</span> is the diode resistance
(<span class="math notranslate nohighlight">\(R_{\mathrm{on}}\)</span> if <span class="math notranslate nohighlight">\(V_s &gt; V_o\)</span>;
<span class="math notranslate nohighlight">\(R_{\mathrm{off}}\)</span> otherwise).
The numerical solution of the above ODE obtained with the RKF45 method
is shown below.</p>
<a class="reference internal image-reference" href="_images/impl4_plots.png"><img alt="RKF45 results for half-wave rectifier" src="_images/impl4_plots.png" style="width: 550px;" /></a>
<p>The charging and discharging intervals can be clearly identified –
charging takes place when the diode current is non-zero; otherwise,
the capacitor discharges through the load resistor.
When the diode conducts, the circuit time constant is
<span class="math notranslate nohighlight">\(\tau _1= (R_{\mathrm{on}}\parallel R)\,C\)</span>
(approximately <span class="math notranslate nohighlight">\(R_{\mathrm{on}}C\)</span>); otherwise it is <span class="math notranslate nohighlight">\(\tau _2 =R\,C\)</span>.
The RKF45 method – like other conditionally stable methods – requires
that the time step be of the order of the circuit time constant.
Since <span class="math notranslate nohighlight">\(\tau _ 1 \ll \tau _2\)</span>,
the time step used by the RKF45 algorithm is much smaller in the
charging phase compared to the discharging phase, as
seen in the figure. If we use a smaller value
of <span class="math notranslate nohighlight">\(R_{\mathrm{on}}\)</span>, <span class="math notranslate nohighlight">\(\tau _1\)</span> becomes smaller, and smaller time
steps get forced.</p>
<p>On the other hand, the BE or TRZ method would not be constrained by
stability considerations at all, and for these methods, a much larger
time step can be selected as long as it gives sufficient accuracy.
For the half-wave rectifier example, <span class="math notranslate nohighlight">\(20\,\mu {\textrm{sec}}\)</span> is suitable,
<em>irrespective</em> of the value of <span class="math notranslate nohighlight">\(R_{\mathrm{on}}\)</span>.</p>
</div>
<div class="section" id="some-practical-issues">
<span id="sec-practical-issues"></span><h3>Some practical issues<a class="headerlink" href="#some-practical-issues" title="Permalink to this headline">¶</a></h3>
<p>We have already covered the most important aspects of
numerical methods for solving ODEs: (a) comparison of
explicit and implicit methods with respect to computation
time, (b) accuracy (order) of a method, (c) constraints
imposed on the time step by stability considerations of a method.
In addition, we need to understand some specific situations which arise
in circuit simulation.</p>
<div class="section" id="oscillatory-circuits">
<span id="sec-osc"></span><h4>Oscillatory circuits<a class="headerlink" href="#oscillatory-circuits" title="Permalink to this headline">¶</a></h4>
<p>Consider an <span class="math notranslate nohighlight">\(LC\)</span> circuit without any resistance (see figure)
and with the initial conditions,
<span class="math notranslate nohighlight">\(v_C(0) = 1\,{\textrm{V}}\)</span>,
<span class="math notranslate nohighlight">\(i_L(0) = 0\,{\textrm{A}}\)</span>.</p>
<a class="reference internal image-reference" href="_images/impl8a.png"><img alt="LC circuit" src="_images/impl8a.png" style="width: 650px;" /></a>
<p>The circuit equations can be described by the following set of ODEs.</p>
<div class="math notranslate nohighlight" id="equation-eq-osc-1">
<span class="eqno">(125)<a class="headerlink" href="#equation-eq-osc-1" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
\displaystyle\frac{dv_C}{dt} &amp;=
-\displaystyle\frac{1}{C}\,i_L
\,, \\
\displaystyle\frac{di_L}{dt} &amp;=
\displaystyle\frac{1}{L}\,v_C
\,,
\end{align}\end{split}\]</div>
<p>with the analytic solution given by</p>
<div class="math notranslate nohighlight" id="equation-eq-osc-2">
<span class="eqno">(126)<a class="headerlink" href="#equation-eq-osc-2" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
v_C &amp;= \cos (\omega t) \,, \\
i_L &amp;= \sin (\omega t) \,,
\end{align}\end{split}\]</div>
<p>with <span class="math notranslate nohighlight">\(\omega = 1/\sqrt{LC}\)</span>. We will consider <span class="math notranslate nohighlight">\(L = 1\,{\textrm{H}}\)</span>,
<span class="math notranslate nohighlight">\(C = 1\,{\textrm{F}}\)</span> which gives the frequency of oscillation
<span class="math notranslate nohighlight">\(f_0 = 1/2\pi\,{\textrm{Hz}}\)</span>, i.e., a period <span class="math notranslate nohighlight">\(T = 2\pi\,{\textrm{sec}}\)</span>.
The numerical results for <span class="math notranslate nohighlight">\(v_C(t)\)</span> obtained with the
BE, TRZ, and BDF2 methods along with the analytic (exact) solution
are shown in the figure.
The TRZ method maintains the amplitude of <span class="math notranslate nohighlight">\(v_C(t)\)</span> constant whereas
the BE and BDF2 methods lead to an artificial reduction (damping) of the
amplitude with time. Clearly, the BE and BDF2 methods are not suitable
for purely oscillatory circuits or for circuits with small amount of
natural damping. In such cases, the TRZ method should be used.</p>
<p>Although the TRZ method does not result in an amplitude error, it does
give a phase error, i.e., the phase of <span class="math notranslate nohighlight">\(v_C(t)\)</span> differs from the expected
phase as time increases. To observe the phase error, expand the plot (zoom in),
and look at the exact and TRZ results; you will see the phase error growing
with time. The phase error can be reduced by selecting a smaller time step.</p>
</div>
<div class="section" id="ringing">
<span id="sec-ringing"></span><h4>Ringing<a class="headerlink" href="#ringing" title="Permalink to this headline">¶</a></h4>
<p>Consider the RC circuit shown in the figure. The component values are
<span class="math notranslate nohighlight">\(R_1 = R_2 = R_3 = 1\,\Omega\)</span>,
<span class="math notranslate nohighlight">\(C_1 = C_2 = C_3 = 1\,{\textrm{F}}\)</span>,
<span class="math notranslate nohighlight">\(V_C(0) = 0\,{\textrm{V}}\)</span> for all capacitors. A step
input going from <span class="math notranslate nohighlight">\(0\,{\textrm{V}}\)</span> to <span class="math notranslate nohighlight">\(1\,{\textrm{V}}\)</span> at <span class="math notranslate nohighlight">\(t = 0\)</span> is applied.</p>
<a class="reference internal image-reference" href="_images/impl10a.png"><img alt="ringing" src="_images/impl10a.png" style="width: 600px;" /></a>
<p>The time constants for this circuit are 0.31, 0.64, and 5.05 seconds,
the smallest being <span class="math notranslate nohighlight">\(\tau _{\mathrm{min}} = 0.31\,{\textrm{sec}}\)</span>.
BE and TRZ results with a relatively large time step are shown in the
figure. Sine the time step (<span class="math notranslate nohighlight">\(5\,{\textrm{sec}}\)</span>) is much larger than
<span class="math notranslate nohighlight">\(\tau _{\mathrm{min}}\)</span>, neither of the two methods can
track closely the expected solution.
However, there is a substantial difference
in the nature of the deviation of the numerical solution from the
exact solution – With the TRZ method, the numerical solution
<em>overshoots</em> the exact solution, hovers around it in an
oscillatory manner, and finally returns to the expected value when
the transients have vanished. This phenomenon, which is specifically
associated with the TRZ method, is called “ringing.” The BE result, in contrast,
approaches the exact solution without overshooting.</p>
<p>Is ringing relevant in practice? Are we ever going to use a time step
which is much larger than <span class="math notranslate nohighlight">\(\tau _{\mathrm{min}}\)</span>?
Yes, the situation does arise in practice, and we should therefore be
watchful. For example, in a typical power electronic circuit, there is frequent
switching activity. Whenever a switch closes, we can expect transients.
Since the switch resistance is small,
<span class="math notranslate nohighlight">\(\tau _{\mathrm{min}}\)</span> is also small, typically much smaller than the time
scale on which we want to resolve the transient. In other words, in such cases,
the time step would be often much larger than
<span class="math notranslate nohighlight">\(\tau _{\mathrm{min}}\)</span>, and we can expect ringing to occur if
the TRZ method is used. If there is a good reason for using the TRZ method
for the specific simulation of interest,
the time step should be suitably reduced in order to avoid ringing.</p>
</div>
</div>
<div class="section" id="tr-bdf2-method">
<span id="sec-trbdf2"></span><h3>TR-BDF2 method<a class="headerlink" href="#tr-bdf2-method" title="Permalink to this headline">¶</a></h3>
<p>The TR-BDF2 method is a combination of TRZ and BDF2 methods.
In this method [Bank, 1992], the time interval <span class="math notranslate nohighlight">\(h\)</span> from <span class="math notranslate nohighlight">\(t_n\)</span>
to <span class="math notranslate nohighlight">\(t_{n+1}\)</span> is divided into two intervals, as shown in the
figure.</p>
<a class="reference internal image-reference" href="_images/impl6.png"><img alt="TR-BDF2 method" src="_images/impl6.png" style="width: 350px;" /></a>
<p>The TRZ method is used to go from <span class="math notranslate nohighlight">\(x_n\)</span> to <span class="math notranslate nohighlight">\(x_{n+\gamma}\)</span>
(i.e., the numerical solution at <span class="math notranslate nohighlight">\(t_{n+\gamma} \equiv t_n + \gamma h\)</span>).
In the second step, the BDF2 method is used (using the three points,
<span class="math notranslate nohighlight">\(t_n\)</span>, <span class="math notranslate nohighlight">\(t_{n+\gamma}\)</span>, and <span class="math notranslate nohighlight">\(t_{n+1}\)</span>),
to compute <span class="math notranslate nohighlight">\(x_{n+1}\)</span>. The constant
<span class="math notranslate nohighlight">\(\gamma\)</span> is selected such that the TRZ and BDF2
Jacobian matrices are identical (which means that the same
<span class="math notranslate nohighlight">\(LU\)</span> factorisation can be used in the TRZ and BDF2 steps).
This leads to the following condition:</p>
<div class="math notranslate nohighlight" id="equation-eq-trbdf2-1">
<span class="eqno">(127)<a class="headerlink" href="#equation-eq-trbdf2-1" title="Permalink to this equation">¶</a></span>\[\displaystyle\frac{2}{\gamma}
= \displaystyle\frac{2-\gamma}{1-\gamma}\,,\]</div>
<p>or <span class="math notranslate nohighlight">\(\gamma = 2-\sqrt{2} \approx 0.59\)</span>.</p>
<p>The TR-BDF2 method has the following advantages.</p>
<ul class="simple">
<li>It does not exhibit ringing.</li>
<li>Although BDF2 is a two-step method,
TR-BDF2 is a single-step method since the solution at
<span class="math notranslate nohighlight">\(t_{n+\gamma}\)</span> is an intermediate result in going from <span class="math notranslate nohighlight">\(t_n\)</span>
to <span class="math notranslate nohighlight">\(t_{n+1}\)</span>. Therefore, no special procedure for starting
is required.</li>
<li>The TR-BDF2 method can be used for auto (adaptive) time stepping
by estimating the LTE and comparing it with a user-specified
tolerance.</li>
</ul>
</div>
<div class="section" id="systematic-assembly-of-circuit-equations">
<span id="sec-mna-trns"></span><h3>Systematic assembly of circuit equations<a class="headerlink" href="#systematic-assembly-of-circuit-equations" title="Permalink to this headline">¶</a></h3>
<p>A circuit simulator like SPICE must be able to handle any general
circuit topology, and it should get the solution in an efficient
manner. In this section, we will see how a general circuit involving
time derivatives (e.g., in the form of capacitors and inductors)
is treated in a circuit simulator.</p>
<p>Consider the circuit shown below.</p>
<a class="reference internal image-reference" href="_images/impl11.png"><img alt="circuit example" src="_images/impl11.png" style="width: 320px;" /></a>
<p>The following equations
describe the circuit behaviour, taking into account the relationship to
be satisfied for each element in the circuit.</p>
<div class="math notranslate nohighlight" id="equation-eq-dae-3">
<span class="eqno">(128)<a class="headerlink" href="#equation-eq-dae-3" title="Permalink to this equation">¶</a></span>\[\begin{align}
C\,\displaystyle\frac{dv_C}{dt}
&amp; = &amp;
G_1(V_s-V_2) - i_L\,,
L\,\displaystyle\frac{di_L}{dt}
&amp; = &amp;
V_3\,,
i_L  &amp; = &amp; G_2(V_2-V_3)\,,
\end{align}\]</div>
<p>where
<span class="math notranslate nohighlight">\(G_1 = 1/R_1\)</span>.
<span class="math notranslate nohighlight">\(G_2 = 1/R_2\)</span>.
Note that the above system of equation is a “mixed” system –
The first two equations are ODEs whereas the last equation is
an algebraic equation.
Such a set of equations is called “Differential-algebraic equations” (DAEs).
In some cases, it may be possible to manipulate the equations to
eliminate the algebraic equations and reduce the original set to an equivalent
set of ODEs.
However, that is not possible in general, especially when nonlinear terms are involved.</p>
<p>How did we come up these equations?
We knew that the equations for the capacitor current and inductor voltage must
be included somewhere. We looked at the circuit and found that there is a KCL
which involves the capacitor current. Similarly, there is a node voltage which is
the same as the inductor voltage. We then invoked the circuit topology and wrote
the equations such that they describe the circuit completely.
In other words, we used our <em>intuition</em> about circuits.
Unfortunately, this is not a <em>systematic</em> approach and is therefore of no
particular use in writing a general-purpose circuit simulator.
Instead of an <em>ad hoc</em> approach, we can use a systematic approach we
have already seen before – the MNA approach –
and write the circuit equations as</p>
<div class="math notranslate nohighlight" id="equation-eq-mnatrns-1">
<span class="eqno">(129)<a class="headerlink" href="#equation-eq-mnatrns-1" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
i_s + G_1(V_1-V_2) &amp;= 0 \,, \\
G_1(V_2-V_1) + G_2(V_2-V_3) + i_C &amp;= 0 \,, \\
G_2(V_3-V_2) + i_L &amp;= 0 \,, \\
V_1 &amp;= V_s(t)\,,
\end{align}\end{split}\]</div>
<p>where the first three are KCL equations, and the last equation is
the element equation for the voltage source.
Our interest is in obtaining the solution of the above equations for
<span class="math notranslate nohighlight">\(t_{n+1}\)</span> from that available for <span class="math notranslate nohighlight">\(t_n\)</span>. Let us write the above
equations specifically for <span class="math notranslate nohighlight">\(t = t_{n+1}\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-eq-mnatrns-1a">
<span class="eqno">(130)<a class="headerlink" href="#equation-eq-mnatrns-1a" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
i_s^{n+1} + G_1(V_1^{n+1}-V_2^{n+1}) &amp;= 0 \,, \\
G_1(V_2^{n+1}-V_1^{n+1}) + G_2(V_2^{n+1}-V_3^{n+1}) + i_C^{n+1} &amp;= 0 \,, \\
G_2(V_3^{n+1}-V_2^{n+1}) + i_L^{n+1} &amp;= 0 \,, \\
V_1^{n+1} &amp;= V_s(t_{n+1})\,.
\end{align}\end{split}\]</div>
<p>Next, we select a method for discretisation of the time derivatives.
As we have seen earlier, stability constraints restrict the choice to
the BE, TRZ, and BDF2 methods, all of them being implicit in nature.
Note that implicit Runge-Kutta methods are also unconditionally stable,
but they are suitable only when the circuit equations can be written
as a set of ODEs.</p>
<p>Suppose we choose the BE method. The capacitor and inductor currents
(<span class="math notranslate nohighlight">\(i_C^{n+1}\)</span>, <span class="math notranslate nohighlight">\(i_L^{n+1}\)</span>) are then obtained as</p>
<div class="math notranslate nohighlight" id="equation-eq-mnatrns-1b">
<span class="eqno">(131)<a class="headerlink" href="#equation-eq-mnatrns-1b" title="Permalink to this equation">¶</a></span>\[\displaystyle\frac{dV_2}{dt}
= \displaystyle\frac{1}{C}\,i_C
~\rightarrow ~
\displaystyle\frac{V_2^{n+1}-V_2^n}{h}
= \displaystyle\frac{i_C^{n+1}}{C}
~\rightarrow~
i_C^{n+1} = \displaystyle\frac{C}{h}\,(V_2^{n+1}-V_2^n)\,,\]</div>
<div class="math notranslate nohighlight" id="equation-eq-mnatrns-2b">
<span class="eqno">(132)<a class="headerlink" href="#equation-eq-mnatrns-2b" title="Permalink to this equation">¶</a></span>\[\displaystyle\frac{di_L}{dt}
= \displaystyle\frac{1}{L}\,V_3
~\rightarrow ~
\displaystyle\frac{i_L^{n+1}-i_L^n}{h}
= \displaystyle\frac{V_3^{n+1}}{L}
~\rightarrow~
i_L^{n+1} = i_L^n + \displaystyle\frac{h}{L}\,(V_3^{n+1})\,,\]</div>
<p>where <span class="math notranslate nohighlight">\(h = t_{n+1}-t_n\)</span> is the time step. Substituting
for <span class="math notranslate nohighlight">\(i_C^{n+1}\)</span> and <span class="math notranslate nohighlight">\(i_L^{n+1}\)</span> in
Eq. <a class="reference internal" href="#equation-eq-mnatrns-1a">(130)</a>, we get</p>
<div class="math notranslate nohighlight" id="equation-eq-mnatrns-1c">
<span class="eqno">(133)<a class="headerlink" href="#equation-eq-mnatrns-1c" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
G_1 V_1^{n+1}-G_1 V_2^{n+1} + i_s^{n+1}
&amp;= 0 \,, \\
-G_1 V_1^{n+1}
+\left(G_1+G_2+\displaystyle\frac{C}{h}\right)V_2^{n+1}
- G_2 V_3^{n+1}
&amp;= \displaystyle\frac{C}{h}\,V_2^n \,, \\
-G_2 V_2^{n+1}
+\left(G_2+\displaystyle\frac{h}{L}\right)V_3^{n+1}
&amp;= -i_L^n \,, \\
V_1^{n+1}
&amp;= V_s(t_{n+1})\,,
\end{align}\end{split}\]</div>
<p>a linear system of four equations in four variables
(<span class="math notranslate nohighlight">\(V_1^{n+1}\)</span>, <span class="math notranslate nohighlight">\(V_2^{n+1}\)</span>, <span class="math notranslate nohighlight">\(V_3^{n+1}\)</span>, <span class="math notranslate nohighlight">\(i_s^{n+1}\)</span>).
It is now a simple matter of solving this
<span class="math notranslate nohighlight">\({\bf{A}}{\bf{x}} = {\bf{b}}\)</span> type problem to obtain the
numerical solution at <span class="math notranslate nohighlight">\(t_{n+1}\)</span>.
We should keep in mind that solving <span class="math notranslate nohighlight">\({\bf{A}}{\bf{x}} = {\bf{b}}\)</span>
is conceptually simple but can take a significant amount of
computation time when the system is large.</p>
<p>What if there are nonlinear elements in the circuit? Let us consider
the circuit shown in the following figure.</p>
<a class="reference internal image-reference" href="_images/impl12.png"><img alt="nonlinear circuit example" src="_images/impl12.png" style="width: 250px;" /></a>
<p>The diode is described by</p>
<div class="math notranslate nohighlight" id="equation-eq-diode-iv-1">
<span class="eqno">(134)<a class="headerlink" href="#equation-eq-diode-iv-1" title="Permalink to this equation">¶</a></span>\[I_D = I_s\left(e^{V_D/V_T}-1\right).\]</div>
<p>We can write the MNA equations for this circuit as</p>
<div class="math notranslate nohighlight" id="equation-eq-mnatrns-nonlin-1">
<span class="eqno">(135)<a class="headerlink" href="#equation-eq-mnatrns-nonlin-1" title="Permalink to this equation">¶</a></span>\[i_s + i_C = 0,\]</div>
<div class="math notranslate nohighlight" id="equation-eq-mnatrns-nonlin-2">
<span class="eqno">(136)<a class="headerlink" href="#equation-eq-mnatrns-nonlin-2" title="Permalink to this equation">¶</a></span>\[-i_C -i_D + GV_2 = 0 ~ \rightarrow ~
-i_C -I_s\left(e^{-V_2/V_T}-1\right) + GV_2 = 0,\]</div>
<div class="math notranslate nohighlight" id="equation-eq-mnatrns-nonlin-3">
<span class="eqno">(137)<a class="headerlink" href="#equation-eq-mnatrns-nonlin-3" title="Permalink to this equation">¶</a></span>\[V_1 = V_s(t),\]</div>
<p>with <span class="math notranslate nohighlight">\(G = 1/R\)</span>. At <span class="math notranslate nohighlight">\(t = t_{n+1}\)</span>, the equations are</p>
<div class="math notranslate nohighlight" id="equation-eq-mnatrns-nonlin-1a">
<span class="eqno">(138)<a class="headerlink" href="#equation-eq-mnatrns-nonlin-1a" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
i_s^{n+1} + i_C^{n+1} &amp;= 0, \\
- i_C^{n+1} -I_s\left(e^{-V_2^{n+1}/V_T}-1\right) + GV_2^{n+1} &amp;= 0, \\
V_1^{n+1} &amp;= V_s(t_{n+1})\,.
\end{align}\end{split}\]</div>
<p>The next step is to obtain <span class="math notranslate nohighlight">\(i_C^{n+1}\)</span> using the BE approximation
for the capacitor equation:</p>
<div class="math notranslate nohighlight" id="equation-eq-mnatrns-nonlin-1b">
<span class="eqno">(139)<a class="headerlink" href="#equation-eq-mnatrns-nonlin-1b" title="Permalink to this equation">¶</a></span>\[\displaystyle\frac{dv_C}{dt}
= \displaystyle\frac{1}{C}\,i_C
~\rightarrow ~
\displaystyle\frac{v_C^{n+1}-v_C^n}{h}
= \displaystyle\frac{i_C^{n+1}}{C}
~\rightarrow~
i_C^{n+1} = \displaystyle\frac{C}{h}\,\left[(V_1^{n+1}-V_2^{n+1})-(V_1^n-V_2^n)\right],\]</div>
<p>Finally, substituting for <span class="math notranslate nohighlight">\(i_C^{n+1}\)</span> in
Eq. <a class="reference internal" href="#equation-eq-mnatrns-nonlin-1a">(138)</a>, we get</p>
<div class="math notranslate nohighlight" id="equation-eq-mnatrns-nonlin-1c">
<span class="eqno">(140)<a class="headerlink" href="#equation-eq-mnatrns-nonlin-1c" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
i_s^{n+1}
+ \displaystyle\frac{C}{h} V_1^{n+1}
- \displaystyle\frac{C}{h} V_2^{n+1}
- \displaystyle\frac{C}{h}(V_1^n-V_2^n)
&amp;= 0, \\
- \displaystyle\frac{C}{h} V_1^{n+1}
+ \displaystyle\frac{C}{h} V_2^{n+1}
-I_s\left(e^{-V_2^{n+1}/V_T}-1\right) + GV_2^{n+1}
+ \displaystyle\frac{C}{h}(V_1^n-V_2^n)
&amp;= 0, \\
V_1^{n+1} - V_s(t_{n+1}) &amp;= 0.
\end{align}\end{split}\]</div>
<p>We now have a nonlinear set of three equations in three
variables (<span class="math notranslate nohighlight">\(V_1^{n+1}\)</span>, <span class="math notranslate nohighlight">\(V_2^{n+1}\)</span>, <span class="math notranslate nohighlight">\(i_s^{n+1}\)</span>). Generally,
circuit simulators would use the NR method to solve
these equations because of the attractive convergence
properties of the NR method seen earlier. Note that the
NR loop needs to be executed in <em>each</em> time step, i.e.,
the Jacobian equation
<span class="math notranslate nohighlight">\({\bf{J}}\Delta {\bf{x}} = -{\bf{f}}\)</span> must be solved
several times in each time step until the NR process converges.
Obviously, this is an expensive computation but it simply cannot be helped.
Some tricks may be employed to make the NR
process more efficient, e.g., <span class="math notranslate nohighlight">\({\bf{J}}^{-1}\)</span>
from the previous NR iteration can be used if <span class="math notranslate nohighlight">\({\bf{J}}\)</span> has
not changed significantly.</p>
<p>The benefits of the above approach (we will refer to it as the
“DAE approach”) outweigh the computational complexity:</p>
<ul class="simple">
<li>Since unconditionally stable methods (BE, TRZ, BDF2) are used,
stiff circuits can be handled without very small time steps.</li>
<li>Algebraic loops do not pose any special problem since the
set of differential-algebraic equations is solved
directly, without any approximations.</li>
</ul>
</div>
<div class="section" id="adaptive-time-steps-using-nr-convergence">
<span id="sec-mna-auto-nr"></span><h3>Adaptive time steps using NR convergence<a class="headerlink" href="#adaptive-time-steps-using-nr-convergence" title="Permalink to this headline">¶</a></h3>
<p>As we have seen in the <a class="reference internal" href="nr.html#nr"><span class="std std-ref">Newton-Raphson method</span></a> section, the initial guess
plays an important role in deciding whether the NR process
will converge for a given nonlinear problem. This feature can
be used to control the time step in transient simulation. The
solution obtained at <span class="math notranslate nohighlight">\(t_n\)</span> serves as the initial guess for
solving the circuit equations at <span class="math notranslate nohighlight">\(t_{n+1}\)</span>. If <span class="math notranslate nohighlight">\(h \equiv t_{n+1}-t_n\)</span>
is sufficiently small, we expect the initial guess to work well,
i.e., we expect the NR process to converge. If <span class="math notranslate nohighlight">\(h\)</span> is large,
the NR process may not converge, or may take a larger number
of iterations to converge. By monitoring the NR convergence process,
it is possible control the time step.</p>
<p>The flow chart for auto (adaptive) time steps is shown below.</p>
<a class="reference internal image-reference" href="_images/nrauto2.png"><img alt="nonlinear circuit flowchart" src="_images/nrauto2.png" style="width: 600px;" /></a>
<p>The basic idea is to allow only a certain maximum number
<span class="math notranslate nohighlight">\(N_{\mathrm{NR}}^{\mathrm{max}}\)</span>
of NR iterations at each time point. If the NR process does not
converge, it means that the time step being taken is too large,
and it needs to be reduced (by a factor <span class="math notranslate nohighlight">\(k_{\mathrm{down}}\)</span>).
However, if the NR process consistently converges in less than
<span class="math notranslate nohighlight">\(N_{\mathrm{NR}}^{\mathrm{max}}\)</span> iterations, it means that a small
time step is not necessary any longer, and we then increase
it (by a factor <span class="math notranslate nohighlight">\(k_{\mathrm{up}}\)</span>).
In this manner, the step size is made small
when required but is allowed to become larger when convergence
is easier. In practice, this means that small time steps are
forced when the solution is varying rapidly, and large time
steps are used when the solution is varying gradually.</p>
<p>Application of the above procedure to an oscillator circuit
is shown in the following figure.
The parameter values are
<span class="math notranslate nohighlight">\(R_1 = R_2 = 1\,{\textrm{k}}\Omega\)</span>,
<span class="math notranslate nohighlight">\(R_0 = 100\,\Omega\)</span>,
<span class="math notranslate nohighlight">\(C = 1\,\mu {\textrm{F}}\)</span>,
<span class="math notranslate nohighlight">\(C_0 = 0.1\,\mu {\textrm{F}}\)</span>,
<span class="math notranslate nohighlight">\(V_{IL} = 1 \,{\textrm{V}}\)</span>,
<span class="math notranslate nohighlight">\(V_{IH} = 4 \,{\textrm{V}}\)</span>,
<span class="math notranslate nohighlight">\(V_{OL} = 0 \,{\textrm{V}}\)</span>,
<span class="math notranslate nohighlight">\(V_{OH} = 5 \,{\textrm{V}}\)</span>,
<span class="math notranslate nohighlight">\(h_{\mathrm{min}} = 10^{-9} \,{\textrm{sec}}\)</span>,
<span class="math notranslate nohighlight">\(h_{\mathrm{max}} = 10^{-4} \,{\textrm{sec}}\)</span>,
<span class="math notranslate nohighlight">\(k_{\mathrm{up}} = 1.1\)</span>,
<span class="math notranslate nohighlight">\(k_{\mathrm{down}} = 0.8\)</span>,
<span class="math notranslate nohighlight">\(N_{\mathrm{NR}}^{\mathrm{max}} = 10\)</span>.</p>
<a class="reference internal image-reference" href="_images/nrauto1.png"><img alt="nonlinear circuit flowchart" src="_images/nrauto1.png" style="width: 500px;" /></a>
<p>The output voltage <span class="math notranslate nohighlight">\(V_4\)</span> controls the switch – when <span class="math notranslate nohighlight">\(V_4\)</span> is
high, the switch turns on; otherwise, it is off. Note that,
when <span class="math notranslate nohighlight">\(V_4\)</span> changes from low to high (or high to low), small
time steps get forced. As <span class="math notranslate nohighlight">\(V_4\)</span> settles down, the time steps
become progressively larger, capped finally by <span class="math notranslate nohighlight">\(h_{\mathrm{max}}\)</span>.</p>
</div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>[Lapidus, 1971] L. Lapidus and J.H. Seinfeld,
<em>Numerical Solution of Ordinary Differential Equations</em>.
New York: Academic Press, 1971.</li>
<li>[McCalla, 1987] W.J. McCalla,
<em>Fundamentals of Computer-Aided Circuit Simulation</em>.
Boston: Kluwer Academic, 1987.</li>
<li>[Bank, 1992] R.E. Bank, W.M. Coughran, W. Fichtner, E.H. Grosse, D.J. Rose, and R.K. Smith,
“Transient simulation of silicon devices and circuits”,
<em>IEEE Trans. Electron Devices</em>, vol. 32, pp. 1992-2006, 1992.</li>
<li>[Shampine, 1994] L.F. Shampine, <em>Numerical Solution of Ordinary Differential Equations</em>.
New York: Chapman and Hall, 1994.</li>
<li>[Burden, 2001] R.L. Burden and J.D. Faires, <em>Numerical Analysis</em>. Singapore: Thomson, 2001.</li>
<li>[Patil, 2009] M.B. Patil, V. Ramanarayanan, and V.T. Ranganathan,
<em>Simulation of power electronic circuits</em>.
New Delhi: Narosa, 2009.</li>
</ul>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">GSEIM</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">GSEIM Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="elements.html">Blocks and ports</a></li>
<li class="toctree-l1"><a class="reference internal" href="new_project.html">Creating a new project</a></li>
<li class="toctree-l1"><a class="reference internal" href="organisation.html">GSEIM Organisation</a></li>
<li class="toctree-l1"><a class="reference internal" href="templates.html">Element templates</a></li>
<li class="toctree-l1"><a class="reference internal" href="solve.html">Solve Blocks</a></li>
<li class="toctree-l1"><a class="reference internal" href="subckt.html">Subcircuits</a></li>
<li class="toctree-l1"><a class="reference internal" href="bedocs.html">Block Documents</a></li>
<li class="toctree-l1"><a class="reference internal" href="proj_list.html">GSEIM projects</a></li>
<li class="toctree-l1"><a class="reference internal" href="mna.html">Modified nodal analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="nr.html">Newton-Raphson method</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Numerical methods for ODEs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#explicit-methods">Explicit methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#forward-euler-method">Forward Euler method</a></li>
<li class="toctree-l3"><a class="reference internal" href="#runge-kutta-method-of-order-4">Runge-Kutta method of order 4</a></li>
<li class="toctree-l3"><a class="reference internal" href="#system-of-odes">System of ODEs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#adaptive-time-step">Adaptive time step</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stability">Stability</a></li>
<li class="toctree-l3"><a class="reference internal" href="#application-to-flow-graphs">Application to flow graphs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#algebraic-loops">Algebraic loops</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#implicit-methods">Implicit methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#be-trz-and-bdf2-methods">BE, TRZ, and BDF2 methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="#implicit-stability">Stability</a></li>
<li class="toctree-l3"><a class="reference internal" href="#some-practical-issues">Some practical issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tr-bdf2-method">TR-BDF2 method</a></li>
<li class="toctree-l3"><a class="reference internal" href="#systematic-assembly-of-circuit-equations">Systematic assembly of circuit equations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#adaptive-time-steps-using-nr-convergence">Adaptive time steps using NR convergence</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ssw.html">SSW computation</a></li>
<li class="toctree-l1"><a class="reference internal" href="startup.html">Start-up simulation</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="nr.html" title="previous chapter">Newton-Raphson method</a></li>
      <li>Next: <a href="ssw.html" title="next chapter">SSW computation</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2022, Mahesh Patil.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.8.5</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.8</a>
      
      |
      <a href="_sources/numerical.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>